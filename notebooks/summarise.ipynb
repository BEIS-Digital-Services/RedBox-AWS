{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from http import HTTPStatus\n",
    "from typing import Annotated\n",
    "from uuid import UUID\n",
    "\n",
    "from fastapi import Depends, FastAPI, HTTPException, WebSocket\n",
    "from fastapi.encoders import jsonable_encoder\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain_community.chat_models import ChatLiteLLM\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_elasticsearch import ApproxRetrievalStrategy, ElasticsearchStore\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "from core_api.src.auth import get_user_uuid\n",
    "from redbox.llm.prompts.chat import (\n",
    "    CONDENSE_QUESTION_PROMPT,\n",
    "    STUFF_DOCUMENT_PROMPT,\n",
    "    WITH_SOURCES_PROMPT,\n",
    ")\n",
    "from redbox.model_db import MODEL_PATH\n",
    "from redbox.models import EmbeddingModelInfo, Settings\n",
    "from redbox.models.chat import ChatRequest, ChatResponse, SourceDocument\n",
    "\n",
    "\n",
    "env = Settings(_env_file=\"../.env\")\n",
    "\n",
    "embedding_model = SentenceTransformerEmbeddings(model_name=env.embedding_model, cache_folder=\"../models/\")\n",
    "\n",
    "es = Elasticsearch(\n",
    "    hosts=[\n",
    "        {\n",
    "            \"host\": \"localhost\",\n",
    "            \"port\": env.elastic.port,\n",
    "            \"scheme\": env.elastic.scheme,\n",
    "        }\n",
    "    ],\n",
    "    basic_auth=(env.elastic.user, env.elastic.password),\n",
    ")\n",
    "\n",
    "if env.elastic.subscription_level == \"basic\":\n",
    "    strategy = ApproxRetrievalStrategy(hybrid=False)\n",
    "elif env.elastic.subscription_level in [\"platinum\", \"enterprise\"]:\n",
    "    strategy = ApproxRetrievalStrategy(hybrid=True)\n",
    "\n",
    "vector_store = ElasticsearchStore(\n",
    "    es_connection=es,\n",
    "    index_name=\"redbox-data-chunk\",\n",
    "    embedding=embedding_model,\n",
    "    strategy=strategy,\n",
    "    vector_query_field=\"embedding\",\n",
    ")\n",
    "\n",
    "llm = ChatLiteLLM(\n",
    "    model=env.openai_model,\n",
    "    streaming=True,\n",
    "    azure_key=env.azure_openai_api_key,\n",
    "    api_version=env.openai_api_version,\n",
    "    api_base=env.azure_openai_endpoint,\n",
    "    max_tokens=4_096,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarisation scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "    \n",
    "# setup = RunnablePassthrough.assign(documents=context | format_docs, sources=context)\n",
    "#     runnable = setup | {\n",
    "#         \"response\": prompt | llm,\n",
    "#         \"sources\": itemgetter(\"sources\"),\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.prompt_template import format_document\n",
    "from redbox.llm.prompts.core import _core_redbox_prompt\n",
    "\n",
    "doc_prompt = PromptTemplate.from_template(\"{page_content}\")\n",
    "\n",
    "chat_history = [\n",
    "    (\"system\", _core_redbox_prompt),\n",
    "    # (\"placeholder\", \"{messages}\")\n",
    "    (\"human\", \"Summarize the following content:\\n\\n{content}\"),\n",
    "]\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "chain = (\n",
    "    # {\n",
    "    #     \"content\": lambda docs: \"\\n\\n\".join(\n",
    "    #         format_document(doc, doc_prompt) for doc in docs\n",
    "    #     )\n",
    "    # }\n",
    "    RunnablePassthrough.assign(content=ChatPromptTemplate.from_messages(chat_history) | format_docs)\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = [\n",
    "    (\"human\", \"Can you always refer to BEIS as the Department for Business, Energy and Industrial Strategy from now on?\"),\n",
    "    (\"ai\", \"Of course. In future responses I will always expand the BEIS acronym.\")\n",
    "]\n",
    "\n",
    "chain.invoke(\n",
    "    input={\n",
    "        \"content\": docs,\n",
    "        \"messages\": conversation\n",
    "    }\n",
    ")\n",
    "chain.invoke(\n",
    "    input={\n",
    "        \"content\": docs,\n",
    "        \"messages\": conversation\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(chain)\n",
    "# chain.input_schema\n",
    "chain.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = get_file_as_documents(file_uuid=UUID(\"d6cdd5a8-5ea5-4f7b-b09c-80d4bb64c266\"), user_uuid=UUID(\"b92ebddb-a77e-4ed7-81b9-a2f7ce814ef5\"), max_tokens=1_000)\n",
    "\n",
    "res = chain.invoke({\"content\": docs})\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary_runnable(\n",
    "    llm: ChatLiteLLM,\n",
    "    init_messages: Optional[list[ChatMessage]] = None,\n",
    ") -> RunnableWithMessageHistory:\n",
    "    if init_messages is None:\n",
    "        init_messages = [\n",
    "            (\"system\", _core_redbox_prompt),\n",
    "            (\"human\", _with_sources_template),\n",
    "        ]\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(init_messages)\n",
    "    context = itemgetter(\"report_request\") | retriever\n",
    "    setup = RunnablePassthrough.assign(documents=context | format_docs, sources=context)\n",
    "    runnable = setup | {\n",
    "        \"response\": prompt | llm,\n",
    "        \"sources\": itemgetter(\"sources\"),\n",
    "    }\n",
    "\n",
    "    return runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from redbox.models.file import Metadata\n",
    "from functools import reduce\n",
    "from redbox.storage import ElasticsearchStorageHandler\n",
    "\n",
    "storage_handler = ElasticsearchStorageHandler(es_client=es, root_index=env.elastic_root_index)\n",
    "\n",
    "def get_file_as_documents(\n",
    "    file_uuid: UUID,\n",
    "    user_uuid: UUID,\n",
    "    storage_handler: ElasticsearchStorageHandler = storage_handler,\n",
    "    max_tokens: int | None = None\n",
    ") -> list[Document]:\n",
    "    \"\"\"Gets a file as LangChain Documents, splitting it by max_tokens.\"\"\"\n",
    "    documents: list[Document] = []\n",
    "    chunks_unsorted = storage_handler.get_file_chunks(parent_file_uuid=file_uuid, user_uuid=user_uuid)\n",
    "    chunks = sorted(chunks_unsorted, key=lambda x: x.index)\n",
    "\n",
    "    token_count: int = 0\n",
    "    n = max_tokens or float(\"inf\")\n",
    "    page_content: list[str] = []\n",
    "    metadata: list[Metadata | None] = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        if token_count + chunk.token_count >= n:\n",
    "            document = Document(\n",
    "                page_content=\" \".join(page_content),\n",
    "                metadata=reduce(Metadata.merge, metadata),\n",
    "            )\n",
    "            documents.append(document)\n",
    "            token_count = 0\n",
    "            page_content = []\n",
    "            metadata = []\n",
    "\n",
    "        page_content.append(chunk.text)\n",
    "        metadata.append(chunk.metadata)\n",
    "        token_count += chunk.token_count\n",
    "\n",
    "    if len(page_content) > 0:\n",
    "        document = Document(\n",
    "            page_content=\" \".join(page_content),\n",
    "            metadata=reduce(Metadata.merge, metadata),\n",
    "        )\n",
    "        documents.append(document)\n",
    "\n",
    "    return documents\n",
    "\n",
    "get_file_as_documents(file_uuid=UUID(\"d6cdd5a8-5ea5-4f7b-b09c-80d4bb64c266\"), user_uuid=UUID(\"b92ebddb-a77e-4ed7-81b9-a2f7ce814ef5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch.helpers import scan\n",
    "\n",
    "\n",
    "chat_request_body = {\n",
    "    \"message_history\": [\n",
    "        {\"text\": \"You are a helpful AI Assistant\", \"role\": \"system\"},\n",
    "        {\"text\": \"What is AI?\", \"role\": \"user\"},\n",
    "    ]\n",
    "}\n",
    "\n",
    "chat_request = ChatRequest(**chat_request_body)\n",
    "\n",
    "def summarise(\n",
    "    chat_request: ChatRequest,\n",
    "    file_uuid: UUID,\n",
    "    user_uuid: UUID = UUID(\"b92ebddb-a77e-4ed7-81b9-a2f7ce814ef5\"),\n",
    "    llm: ChatLiteLLM = llm,\n",
    "    storage_handler: ElasticsearchStorageHandler = storage_handler,\n",
    ") -> ChatResponse:\n",
    "    # get full doc from vector store\n",
    "    document = get_file_as_documents(file_uuid=file_uuid, user_uuid=user_uuid, storage_handler=storage_handler)\n",
    "    # stuff raw vanilla prompt\n",
    "\n",
    "    # return\n",
    "\n",
    "x = summarise(\n",
    "    chat_request=chat_request,\n",
    "    file_uuid=UUID(\"d6cdd5a8-5ea5-4f7b-b09c-80d4bb64c266\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redbox-Vh_-Fb0j-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
