{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Connecting to self managed Elasticsearch\n",
      "INFO:root:Elasticsearch host = localhost\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: *** No rule to make target `eval_backend'.  Stop.\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import typing as t\n",
    "import json\n",
    "import jsonlines\n",
    "import pickle\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "\n",
    "from redbox.model_db import SentenceTransformerDB\n",
    "from redbox.models import Settings\n",
    "from redbox.parsing import chunk_file\n",
    "from redbox.models.file import File, Chunk\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "from mypy_boto3_s3.client import S3Client\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "ENV = Settings()\n",
    "ENV.minio_host = \"localhost\"\n",
    "ENV.elastic.host = \"localhost\"\n",
    "\n",
    "S3_CLIENT = ENV.s3_client()\n",
    "ES_CLIENT = ENV.elasticsearch_client()\n",
    "\n",
    "!cd ../.. && make eval_backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create evaluation dataset for Redbox RAG chat  <a class=\"anchor\" id=\"title\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Redbox RAG chat on one stable, numbered version of these data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before running this notebook**\n",
    "\n",
    "Set the version of the evaluation dataset you are creating **[HERE](#setversion)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents <a class=\"anchor\" id=\"toc\"></a>\n",
    "* [Overview](#overview)\n",
    "* [Set version of the evaluation dataset](#setversion)\n",
    "* [Select files for creating evaluation dataset](#files)\n",
    "* [Imports](#imports)\n",
    "* [Generate evaluation dataset](#ragas)\n",
    "* [Save evaluation dataset](#save)\n",
    "* [Pre-embed the documents](#embed)\n",
    "* [Troubleshooting](#troubleshooting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview <a class=\"anchor\" id=\"overview\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is really important to version the evaluations we are doing, including the input data used to generate evaluation datasets.\n",
    "\n",
    "This notebook uses the files you select in combination with the RAGAS framework to generate synthetic data. Two different LLMs are used, one for the 'generator' and one for the 'critic'.\n",
    "\n",
    "Please be aware the generating synthetic data will incur LLM API costs.\n",
    "\n",
    "The purpose of this note book is to **create a filesystem with a versioned dataset**. This means:\n",
    "\n",
    "* Raw files, like documents nad PDFs\n",
    "* An evaluation dataset, containing questions and answers\n",
    "* Embedded chunks for those raw files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a troubleshooting section at the end of this notebook [Troubleshooting](#troubleshooting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Redbox RAG chat on one stable, numbered version of these data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set the version of the evaluation dataset you will be creating in this notebook in the cell below**  <a class=\"anchor\" id=\"setversion\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_VERSION = \"0.1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MODEL = ENV.embedding_model\n",
    "INDEX = f\"{DATA_VERSION}-{MODEL.embedding_model_name}\".lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to set up the required folder structure (it will not overwrite folders and files if they already exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd().parents[1]\n",
    "EVALUATION_DIR = ROOT / \"notebooks/evaluation\"\n",
    "\n",
    "V_ROOT = EVALUATION_DIR / f\"data/{DATA_VERSION}\"\n",
    "V_RAW = V_ROOT / \"raw\"\n",
    "V_SYNTHETIC = V_ROOT / \"synthetic\"\n",
    "V_CHUNKS = V_ROOT / \"chunks\"\n",
    "V_RESULTS = V_ROOT / \"results\"\n",
    "V_EMBEDDINGS = V_ROOT / \"embeddings\"\n",
    "\n",
    "V_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "V_RAW.mkdir(parents=True, exist_ok=True)\n",
    "V_SYNTHETIC.mkdir(parents=True, exist_ok=True)\n",
    "V_CHUNKS.mkdir(parents=True, exist_ok=True)\n",
    "V_RESULTS.mkdir(parents=True, exist_ok=True)\n",
    "V_EMBEDDINGS.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's helpful for all calls to share a dummy user. Set that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import UUID\n",
    "\n",
    "USER_UUID = UUID(\"aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select files that you will use to generate versioned evaluation dataset   <a class=\"anchor\" id=\"files\"></a>\n",
    "\n",
    "Now copy all the files you want to use to generate **THIS VERSION** of the evaluation dataset into `notebooks/evaluation/data/{DATA_VERSION}/raw/`\n",
    "\n",
    "Also upload these files to shared Google Drive and the corresponding version number/location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports <a id=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import typing as t\n",
    "import json\n",
    "import jsonlines\n",
    "import pickle\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willlangdale/Library/Caches/pypoetry/virtualenvs/redbox-Vh_-Fb0j-py3.11/lib/python3.11/site-packages/threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "INFO:root:Connecting to self managed Elasticsearch\n",
      "INFO:root:Elasticsearch host = localhost\n"
     ]
    }
   ],
   "source": [
    "from redbox.model_db import SentenceTransformerDB\n",
    "from redbox.models import Settings\n",
    "from redbox.parsing import chunk_file\n",
    "from redbox.models.file import File, Chunk\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "from mypy_boto3_s3.client import S3Client\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetically generate evaluation dataset <a class=\"anchor\" id=\"ragas\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAGAS generating a synthetic test set detailed [HERE](https://docs.ragas.io/en/stable/getstarted/testset_generation.html). Perhaps not as SOTA as DeepEval (validate!), but it creates `input` AND `expected_output` for us. \n",
    "\n",
    "So we are not generating input questions based on our chunking strategy, however, we are using the same files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes about 4 minutes for 4 docs. Consider Langchain `unstructured`\n",
    "loader = DirectoryLoader(V_RAW)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Langchain documents for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_docs_to_jsonl(documents: t.Iterable[Document], file_path: str) -> None:\n",
    "    with jsonlines.open(file_path, mode=\"w\") as writer:\n",
    "        for doc in documents:\n",
    "            writer.write(doc.dict())\n",
    "\n",
    "\n",
    "def load_docs_from_jsonl(file_path) -> t.Iterable[Document]:\n",
    "    documents = []\n",
    "    with jsonlines.open(file_path, mode=\"r\") as reader:\n",
    "        for doc in reader:\n",
    "            documents.append(Document(**doc))\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_docs_to_jsonl(documents, V_CHUNKS / \"documents.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAGAS generator with openai models\n",
    "generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo\") # to match core-api\n",
    "critic_llm = ChatOpenAI(model=\"gpt-4o\") # cheaper model with similar performance\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm,\n",
    "    critic_llm,\n",
    "    embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate testset\n",
    "testset = generator.generate_with_langchain_docs(documents, test_size=10, distributions={simple: 0.4, reasoning: 0.3, multi_context: 0.3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save RAGAS generated testset <a class=\"anchor\" id=\"save\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{V_SYNTHETIC}/ragas_testset.pkl', 'wb') as f:\n",
    "    pickle.dump(testset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert dataframe into a DeepEval compatible CSV & save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_df = testset.to_pandas()\n",
    "\n",
    "# Rename the columns\n",
    "new_column_names = {\n",
    "    'question': 'input',\n",
    "    'contexts': 'context',\n",
    "    'ground_truth': 'expected_output',\n",
    "    # Add more column names here\n",
    "}\n",
    "\n",
    "testset_df_renamed = testset_df.rename(columns=new_column_names)\n",
    "\n",
    "#  DeepEval dataset format requires an 'actual_output' column\n",
    "testset_df_renamed['actual_output'] = ''\n",
    "testset_df_renamed = testset_df_renamed.drop(['evolution_type', 'metadata', 'episode_done'], axis=1)\n",
    "\n",
    "# Convert all columns to string & drop NaN - otherwise DeepEval will throw an Pydantic validation error\n",
    "testset_df_renamed = testset_df_renamed.astype(str)\n",
    "testset_df_renamed = testset_df_renamed.dropna()\n",
    "\n",
    "# save as CSV\n",
    "testset_df_renamed.to_csv(f'{V_SYNTHETIC}/ragas_synthetic_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) View top 5 rows of synthetically generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_df_renamed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-embed the documents for other users <a class=\"anchor\" id=\"embed\"></a>\n",
    "\n",
    "Embeddings take a while. Here we show how to compute and save them for other users.\n",
    "\n",
    "For now we use the chunking strategy from `worker/`, and embed with any models we choose.\n",
    "\n",
    "Ensure the necessary services are running with `make eval_backend`, but all we really need is MinIO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_chunks_to_jsonl(chunks: t.Iterable[Chunk], file_path: Path) -> None:\n",
    "    with jsonlines.open(file_path, mode=\"w\") as writer:\n",
    "        for chunk in chunks:\n",
    "            writer.write(chunk.model_dump_json())\n",
    "\n",
    "def embed_file(\n",
    "    file_path: Path, \n",
    "    data_version: str, \n",
    "    bucket_name: str, \n",
    "    model: SentenceTransformerDB, \n",
    "    user_uuid: UUID = USER_UUID, \n",
    "    s3_client: S3Client = S3_CLIENT\n",
    ") -> list[Chunk]:\n",
    "    key = f\"{data_version}/{file_path.name}\"\n",
    "    file = File(key=key, bucket=bucket_name, creator_user_uuid=user_uuid)\n",
    "    \n",
    "    # Upload to bucket\n",
    "    with open(file_path, 'rb') as f:\n",
    "        s3_client.upload_fileobj(f, bucket_name, key)\n",
    "    \n",
    "    # Chunk\n",
    "    chunks = chunk_file(file=file, s3_client=s3_client)\n",
    "\n",
    "    # Embed\n",
    "    embeddings = [\n",
    "        embedding.embedding \n",
    "        for embedding \n",
    "        in model.embed_sentences([chunk.text for chunk in chunks]).data\n",
    "    ]\n",
    "\n",
    "    # Merge\n",
    "    chunks_embedded = []\n",
    "    for chunk, embedding in zip(chunks, embeddings, strict=True):\n",
    "        chunk_embedded = Chunk(\n",
    "            uuid=chunk.uuid, \n",
    "            created_datetime=chunk.created_datetime, \n",
    "            creator_user_uuid=chunk.creator_user_uuid, \n",
    "            parent_file_uuid=chunk.parent_file_uuid, \n",
    "            index=chunk.index, \n",
    "            text=chunk.text, \n",
    "            metadata=chunk.metadata, \n",
    "            embedding=embedding\n",
    "        )\n",
    "        chunks_embedded.append(chunk_embedded)\n",
    "    \n",
    "    return chunks_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embedded_files = []\n",
    "\n",
    "for file_path in V_RAW.glob(\"*.*\"):\n",
    "    file_chunks_embedded = embed_file(\n",
    "        file_path=file_path,\n",
    "        data_version=DATA_VERSION,\n",
    "        bucket_name=ENV.bucket_name,\n",
    "        model=SentenceTransformerDB(model_name=EMBEDDING_MODEL)\n",
    "    )\n",
    "    all_embedded_files += file_chunks_embedded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting <a class=\"anchor\" id=\"troubleshooting\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Langchain DirectoryLoader Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run into a poppler path error and poppler is installed and can be access from your virtual environment (by running `pdfinfo -v`), then close notebook and restart the Jupyter server from the terminal where the path is correctly set (by running `code notebooks/evaluation/evaluation_dataset_generation.ipynb`) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAGAS synthetically generated evaluation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have found some rows of synthetically generated evaluation data from using the RAGAS framework, includes some NaN and/or not str type, which results in an error for DeepEval metrics, as these data fail Pydantic validation.\n",
    "\n",
    "To avoid this, ensure you turn RAGAS synthetically generated evaluation data to type str and remove rows of data with NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DeepEval framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment, this notebook only loads the evaluation dataset into DeepEval from a CSV. There is a JSON import option that we are not using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redbox-MiicHf1r-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
