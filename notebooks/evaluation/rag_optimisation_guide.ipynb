{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redbox RAG chat optimisation guide  <a class=\"anchor\" id=\"title\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview <a class=\"anchor\" id=\"one-section\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to optimising the generation part of our RAG system, the only thing that we can modify are the `RAG prompts` that are passed with context to the LLM. Other components certainly play into the overall generation evaluation score, such as is the retrieved context of high-quality, but the levers to change these other components are further upstream in the RAG pipeline, and evaluated in Retrieval Evaluation and e2d Evaluation notebooks. These other components are also slower to change compared to prompts, which are just natural language!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently the experimentation time for changing any componenet in Redbox RAG (core-api) is slow. After each change the docker image has to be rebuilt and then the evaluation dataset has to be passed to the updated RAG and subsequent evaluation metrics analysed to see if they improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**An aim for future is to make this experimentation process faster and better tracked**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, this notebook links to all the files where `RAG prompts` can be changed to try and optimise Redbox Core API performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow in this Notebook <a class=\"anchor\" id=\"four-section\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Review the various locations in the codebase where `RAG prompts` are used\n",
    "2. Make a change in one or more of these locations\n",
    "3. Rebuild the core-api docker image (and any other images modified), using `docker compose rebuild --no-cache`\n",
    "4. Follow the rag_e2e_evaluation notebook to generate evaluation score for the modified Redbox RAG based on your changes\n",
    "5. Record your changes in **TBD**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow these steps to run an experiment:\n",
    "1. Make experimental changes to [`RAG prompts`]() - these will be used by the /chat/rag function\n",
    "2. (Optional) Make experimental changes to the [/chat/rag function]() \n",
    "3. Pass the evaluation dataset through the /chat/rag function to general `actual_output` and append these to the evaluation dataset\n",
    "4. Run evaluations on dataset to calcuate generation evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG prompt locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. System Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the `/chat/rag` endpoint it used, a system prompt can be sent, which will be considered by the LLM. In future we may want to consolidate any system prompt being sent in a message with the backend prompts, but for now it is a source of variation/optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from jose import jwt\n",
    "from uuid import UUID\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example `/chat/rag/` endpoint payload. Notice `\"role\": \"system\"` followed by text. You can make the response talk like a pirate if you ask it to here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bearer_token = jwt.encode({\"user_uuid\": str(UUID(\"aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa\"))}, key=\"your-secret-key\", algorithm=\"HS512\")\n",
    "\n",
    "headers = {\n",
    "    'accept': 'application/json',\n",
    "    'Authorization': 'Bearer ' + bearer_token,\n",
    "    'Content-Type': 'application/json',\n",
    "}\n",
    "\n",
    "url = 'http://127.0.0.1:5002/chat/rag'\n",
    "\n",
    "for input in inputs:\n",
    "    data = {\n",
    "        \"message_history\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"text\": \"You are a helpful AI Assistant\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"text\": \"What is AI?\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "    data = response.json()\n",
    "\n",
    "    retrieval_context.append(data['source_documents'])\n",
    "    actual_output.append(data['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Prompts in core.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One prompt, the `_core_redbox_prompt` is located in [core.py](../../redbox/llm/prompts/core.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_core_redbox_prompt = \"\"\"You are RedBox Copilot. An AI focused on helping UK Civil Servants, Political Advisors and\\\n",
    "Ministers triage and summarise information from a wide variety of sources. You are impartial and\\\n",
    "non-partisan. You are not a replacement for human judgement, but you can help humans\\\n",
    "make more informed decisions. If you are asked a question you cannot answer based on your following instructions, you\\\n",
    "should say so. Be concise and professional in your responses. Respond in markdown format.\n",
    "\n",
    "=== RULES ===\n",
    "\n",
    "All responses to Tasks **MUST** be translated into the user's preferred language.\\\n",
    "This is so that the user can understand your responses.\\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check where CORE_REDBOX_PROMPT is used in the codebase\n",
    "CORE_REDBOX_PROMPT = PromptTemplate.from_template(_core_redbox_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Prompts in chat.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 prompts located in [chat.py](../../redbox/llm/prompts/chat.py)\n",
    "\n",
    "Things to experiment with:\n",
    "1. `_with_sources_template`\n",
    "2. `WITH_SOURCES_PROMPT`\n",
    "3. `_stuff_document_template`\n",
    "4. `STUFF_DOCUMENT_PROMPT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_with_sources_template = \"\"\"Given the following extracted parts of a long document and \\\n",
    "a question, create a final answer with Sources at the end.  \\\n",
    "If you don't know the answer, just say that you don't know. Don't try to make \\\n",
    "up an answer.\n",
    "Be concise in your response and summarise where appropriate. \\\n",
    "At the end of your response add a \"Sources:\" section with the documents you used. \\\n",
    "DO NOT reference the source documents in your response. Only cite at the end. \\\n",
    "ONLY PUT CITED DOCUMENTS IN THE \"Sources:\" SECTION AND NO WHERE ELSE IN YOUR RESPONSE. \\\n",
    "IT IS CRUCIAL that citations only happens in the \"Sources:\" section. \\\n",
    "This format should be <DocX> where X is the document UUID being cited.  \\\n",
    "DO NOT INCLUDE ANY DOCUMENTS IN THE \"Sources:\" THAT YOU DID NOT USE IN YOUR RESPONSE. \\\n",
    "YOU MUST CITE USING THE <DocX> FORMAT. NO OTHER FORMAT WILL BE ACCEPTED.\n",
    "Example: \"Sources: <DocX> <DocY> <DocZ>\"\n",
    "\n",
    "Use **bold** to highlight the most question relevant parts in your response.\n",
    "If dealing dealing with lots of data return it in markdown table format.\n",
    "\n",
    "QUESTION: {question}\n",
    "=========\n",
    "{summaries}\n",
    "=========\n",
    "FINAL ANSWER:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WITH_SOURCES_PROMPT = PromptTemplate.from_template(_core_redbox_prompt + _with_sources_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_stuff_document_template = \"<Doc{parent_doc_uuid}>{page_content}</Doc{parent_doc_uuid}>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STUFF_DOCUMENT_PROMPT = PromptTemplate.from_template(_stuff_document_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. LLM being used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also optimise the LLM being used, but please **bear in mind that prompts are per LLM and if you change the LLM you will need to optimise the prompts!**\n",
    "\n",
    "For now, please stick with gpt-3.5-turbo, as we establish a baseline quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Promote optimised prompts into production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you find changes to the prompts above improve the generation evaluation scores, please consider making a PR to update the code in `core_api`. Follow these steps:\n",
    "\n",
    "1. Create a new branch off `main`\n",
    "2. Make changes in the locations listed below\n",
    "3. Run through the e2e RAG evaluation notebook\n",
    "4. If e2e RAG evaluation metrics are improved, please make a PR!\n",
    "\n",
    "All these prompts are locations in [chat.py](../../redbox/llm/prompts/chat.py), except `_core_redbox_prompt` which is located in [core.py](../../redbox/llm/prompts/core.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
