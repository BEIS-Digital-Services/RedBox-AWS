{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground & e2e Evaluation for Redbox RAG chat  <a class=\"anchor\" id=\"title\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents <a class=\"anchor\" id=\"toc\"></a>\n",
    "* [Overview](#one-section)\n",
    "* [Metrics](#two-section)\n",
    "    - [Fathfulness]()\n",
    "    - [Answer Relevancy]()\n",
    "    - [Hallucination]()\n",
    "* [Evaluation Dataset](#three-section)\n",
    "* [Evaluation Workflow in this Notebook](#four-section)\n",
    "* [Prompt Playground](#five-section)\n",
    "    - [RAG prompts](#six-section)\n",
    "* [Generate RAG responses and append them to evaluation dataset](#seven-section)\n",
    "\n",
    "* [eight](#eight-section)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview <a class=\"anchor\" id=\"one-section\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to optimising the generation part of our RAG system, the only thing that we can modify are the `RAG prompts` that are passed with context to the LLM. Other components certainly play into the overall generation evaluation score, such as is the retrieved context of high-quality, but the levers to change these other components are further upstream in the RAG pipeline, and evaluated in Retrieval Evaluation and e2d Evaluation notebooks. These other components are also slower to change compared to prompts, which are just natural language!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to avoid using the /chat/rag endpoint for quick experimentation with `RAG prompts`, as the need to rebuild the core_api docker image, start and stop container etc will really slow down development --> changing prompts is very quick to do, so we want quick evaluation of how these prompt changes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this reason, the /chat/rag endpoint function is in this notebook, and prompts can be changed in a single place, followed by much quicker feedback. If your prompt experiments look good, i.e. they improve generation evalution metrics, then you can consider making these changes in the `core_api` service. Information on where to make the corresponding changesin the the `core_api` service are at the bottom of this notebook. Once you make changes in `core_api` and rebuild, these changes will be reflected in the deployed /chat/rag endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will evaluate RAG generation using metrics described in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics <a class=\"anchor\" id=\"two-section\"></a>\n",
    "\n",
    "#TODO: Add retrieval metrics too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by using 3 DeepEval metrics:\n",
    "- Faithfulness\n",
    "- Answer Relevancy **(what are we taking as 'input'? Raw question or refined question?)**\n",
    "- Hallucination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faithfulness\n",
    "\n",
    "The faithfulness metric measures the quality of your RAG pipeline's generator by evaluating whether the `actual_output` factually aligns with the contents of your `retrieval_context`. `deepeval`'s faithfulness metric is a self-explaining LLM-Eval, meaning it outputs a reason for its metric score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Required Arguments\n",
    "To use the `FaithfulnessMetric`, you need to provide the following arguments when creating an LLMTestCase:\n",
    "\n",
    "- `input`\n",
    "- `actual_output`\n",
    "- `retrieval_context`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer Relevancy\n",
    "The answer relevancy metric measures the quality of your RAG pipeline's generator by evaluating how relevant the actual_output of your LLM application is compared to the provided `input`. `deepeval`'s answer relevancy metric is a self-explaining LLM-Eval, meaning it outputs a reason for its metric score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Required Arguments\n",
    "To use the AnswerRelevancyMetric, you'll have to provide the following arguments when creating an LLMTestCase:\n",
    "\n",
    "- `input`\n",
    "- `actual_output`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hallucination\n",
    "The hallucination metric determines whether your LLM generates factually correct information by comparing the `actual_output` to the provided `context`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Required Arguments\n",
    "To use the HallucinationMetric, you'll have to provide the following arguments when creating an LLMTestCase:\n",
    "\n",
    "- `input`\n",
    "- `actual_output`\n",
    "- `retrieval_context`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup <a class=\"anchor\" id=\"five-section\"></a>\n",
    "\n",
    "Some basic setup for RAG chat function to work during experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add autoreloatd\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Check this autoreload works in vscode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from langchain.prompts.prompt import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mock HTTP Authorization Credentials, used by the RAG chat function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core_api.src.auth import get_user_uuid\n",
    "from fastapi.security import HTTPAuthorizationCredentials\n",
    "from unittest.mock import Mock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock HTTP Authorization Credentials\n",
    "credentials = Mock(spec=HTTPAuthorizationCredentials)\n",
    "credentials.credentials = \"mock_token\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RAG chat function imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain_community.chat_models import ChatLiteLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Dataset <a class=\"anchor\" id=\"three-section\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TODO: Load evaluation dataset for generation evaluation\n",
    "# from deepeval.dataset import EvaluationDataset\n",
    "\n",
    "# dataset = EvaluationDataset()\n",
    "# dataset.add_test_cases_from_json_file(\n",
    "#     # file_path is the absolute path to you .json file\n",
    "#     file_path=\"example.json\",\n",
    "#     input_key_name=\"query\",\n",
    "#     actual_output_key_name=\"actual_output\",\n",
    "#     expected_output_key_name=\"expected_output\",\n",
    "#     context_key_name=\"context\",\n",
    "#     retrieval_context_key_name=\"retrieval_context\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Workflow in this Notebook <a class=\"anchor\" id=\"four-section\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow these steps to run an experiment:\n",
    "1. Make experimental changes to [`RAG prompts`]() - these will be used by the /chat/rag function\n",
    "2. (Optional) Make experimental changes to the [/chat/rag function]() \n",
    "3. Pass the evaluation dataset through the /chat/rag function to general `actual_output` and append these to the evaluation dataset\n",
    "4. Run evaluations on dataset to calcuate generation evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Documents for Evaluation\n",
    "\n",
    "We have a list of docs to use for evaluation. These should continue to be built upon to ensure we cover all different types of documents and content that users of Redbox may require, to ensure we have good evalution coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run MinIO container\n",
    "The file chunker is set up to get files from an s3 bucket. So in order to use the existing `core_api` parsing code as is, we must go through the process of running a local MinIO container and uploading files to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the following steps\n",
    "1. Ensure you have a docker runtime running\n",
    "2. In evaluation folder create `minio/data` directories\n",
    "3. Get the ABSOLUTE path for this minio/data directory on your system - and replace it in the penultimate -v line below\n",
    "2. Run a MinIO container by running the cell below in a terminal window (from https://min.io/docs/minio/container/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "docker run \\\n",
    "   -p 9000:9000 \\\n",
    "   -p 9001:9001 \\\n",
    "   --user $(id -u):$(id -g) \\\n",
    "   --name minio \\\n",
    "   -e \"MINIO_ROOT_USER=minioadmin\" \\\n",
    "   -e \"MINIO_ROOT_PASSWORD=minioadmin\" \\\n",
    "   -v /Users/andy/tw/gen-ai/redbox-copilot/notebook/evaluation/minio/data:/data \\\n",
    "   quay.io/minio/minio server /data --console-address \":9001\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want, go to browser `localhost:9000` and login with the username and password set above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Elasticsearch container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker pull docker.elastic.co/elasticsearch/elasticsearch:8.11.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run an elasticsearch container by running the cell below in a terminal window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "docker run -p 9200:9200 -p 9300:9300 --name elasticsearch \\\n",
    "-e \"discovery.type=single-node\" \\\n",
    "docker.elastic.co/elasticsearch/elasticsearch:8.11.0\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Can we mount a volumne to persist loaded documents, as we built up test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document Upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Pydantic chat models, used by the RAG chat function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minio import Minio\n",
    "from minio.error import S3Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used by the file functions\n",
    "from redbox.models import Chunk, File, FileStatus, Settings\n",
    "from redbox.storage import ElasticsearchStorageHandler\n",
    "from redbox.model_db import SentenceTransformerDB\n",
    "from redbox.parsing.file_chunker import FileChunker\n",
    "# Used by the RAG chat function\n",
    "from redbox.models.chat import ChatMessage, ChatRequest, ChatResponse, SourceDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Logging ===\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "log = logging.getLogger()\n",
    "\n",
    "env = Settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Storage ===\n",
    "# Initialize an ElasticsearchStorageHandler\n",
    "# es = env.elasticsearch_client()\n",
    "from elasticsearch import Elasticsearch\n",
    "es = Elasticsearch(\n",
    "                hosts=[\n",
    "                    {\n",
    "                        \"host\": \"localhost\",\n",
    "                        \"port\": 9200,\n",
    "                        \"scheme\": \"http\",\n",
    "                    }\n",
    "                ],\n",
    "                basic_auth=(\"elastic\", \"redboxpass\"),\n",
    "            )\n",
    "storage_handler = ElasticsearchStorageHandler(es_client=es, root_index=\"redbox-data\")\n",
    "\n",
    "# Initialize a FileChunker\n",
    "chunker = FileChunker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Change needs to be made in chunker.py too**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Object Store ===\n",
    "import boto3\n",
    "def s3_client():\n",
    "    client = boto3.client(\n",
    "        \"s3\",\n",
    "        aws_access_key_id=\"\",\n",
    "        aws_secret_access_key=\"\",\n",
    "        endpoint_url=f\"http://localhost:9000\",\n",
    "    )\n",
    "    return client\n",
    "\n",
    "s3 = s3_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from minio import Minio\n",
    "# from minio.error import S3Error\n",
    "\n",
    "# def get_from_minio(file_path, bucket_name):\n",
    "#     # Create a client with the MinIO server, its access key and secret key.\n",
    "#     client = Minio(\"localhost:9000\", access_key=\"minioadmin\", secret_key=\"minioadmin\", secure=False)\n",
    "\n",
    "#     try:\n",
    "#         # Check if 'bucket_name' exists.\n",
    "#         if client.bucket_exists(bucket_name):\n",
    "#             # Get 'file_path' from bucket 'bucket_name'.\n",
    "#             data = client.get_object(bucket_name, file_path)\n",
    "#             # Read the first kilobyte of data and print it\n",
    "#             print(data.read(1024))\n",
    "#         else:\n",
    "#             print(f'Bucket {bucket_name} does not exist')\n",
    "\n",
    "#     except S3Error as exc:\n",
    "#         print(f'error occurred: {exc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_minio(file_path, bucket_name):\n",
    "    # Create a client with the MinIO server, its access key and secret key.\n",
    "    client = Minio(\"localhost:9000\", access_key=\"minioadmin\", secret_key=\"minioadmin\", secure=False)\n",
    "\n",
    "    try:\n",
    "        # Make 'bucket_name' if not exist.\n",
    "        if not client.bucket_exists(bucket_name):\n",
    "            client.make_bucket(bucket_name)\n",
    "\n",
    "        # Upload 'file_path' as object name in bucket 'bucket_name'.\n",
    "        client.fput_object(bucket_name, file_path, file_path)\n",
    "        print(f'Successfully uploaded {file_path} to {bucket_name}')\n",
    "\n",
    "    except S3Error as exc:\n",
    "        print(f'error occurred: {exc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'BadStatusLine('ÿ\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x7fo\\x01t: localhost:9000\\r\\n')': /redbox-storage-dev?location=\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'BadStatusLine('ÿ\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x7fo\\x01t: localhost:9000\\r\\n')': /redbox-storage-dev?location=\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'BadStatusLine('ÿ\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x7fo\\x01t: localhost:9000\\r\\n')': /redbox-storage-dev?location=\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'BadStatusLine('ÿ\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x7fo\\x01t: localhost:9000\\r\\n')': /redbox-storage-dev?location=\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'BadStatusLine('ÿ\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x7fo\\x01t: localhost:9000\\r\\n')': /redbox-storage-dev?location=\n"
     ]
    },
    {
     "ename": "MaxRetryError",
     "evalue": "HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /redbox-storage-dev?location= (Caused by ProtocolError('Connection aborted.', BadStatusLine('ÿ\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x7fo\\x01t: localhost:9000\\r\\n')))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;31mProtocolError\u001b[0m: ('Connection aborted.', BadStatusLine('ÿ\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x7fo\\x01t: localhost:9000\\r\\n'))",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# This loads to redbox-storage-dev/data_eval/Universal-Basic-Income-Scotland-Report.pdf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Is the 'data_eval' part of the path going to be a problem?\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mupload_to_minio\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUniversal-Basic-Income-Scotland-Report.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mredbox-storage-dev\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 7\u001b[0m, in \u001b[0;36mupload_to_minio\u001b[0;34m(file_path, bucket_name)\u001b[0m\n\u001b[1;32m      3\u001b[0m client \u001b[38;5;241m=\u001b[39m Minio(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocalhost:9000\u001b[39m\u001b[38;5;124m\"\u001b[39m, access_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminioadmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, secret_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminioadmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, secure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Make 'bucket_name' if not exist.\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbucket_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbucket_name\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      8\u001b[0m         client\u001b[38;5;241m.\u001b[39mmake_bucket(bucket_name)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Upload 'file_path' as object name in bucket 'bucket_name'.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/redbox-MiicHf1r-py3.11/lib/python3.11/site-packages/minio/api.py:696\u001b[0m, in \u001b[0;36mMinio.bucket_exists\u001b[0;34m(self, bucket_name)\u001b[0m\n\u001b[1;32m    694\u001b[0m check_bucket_name(bucket_name, s3_check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_url\u001b[38;5;241m.\u001b[39mis_aws_host)\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 696\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbucket_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m S3Error \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/redbox-MiicHf1r-py3.11/lib/python3.11/site-packages/minio/api.py:437\u001b[0m, in \u001b[0;36mMinio._execute\u001b[0;34m(self, method, bucket_name, object_name, body, headers, query_params, preload_content, no_body_trace)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_execute\u001b[39m(\n\u001b[1;32m    426\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    427\u001b[0m         method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    434\u001b[0m         no_body_trace: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    435\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseHTTPResponse:\n\u001b[1;32m    436\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Execute HTTP request.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 437\u001b[0m     region \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_region\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbucket_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_url_open(\n\u001b[1;32m    441\u001b[0m             method,\n\u001b[1;32m    442\u001b[0m             region,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m             no_body_trace\u001b[38;5;241m=\u001b[39mno_body_trace,\n\u001b[1;32m    450\u001b[0m         )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/redbox-MiicHf1r-py3.11/lib/python3.11/site-packages/minio/api.py:494\u001b[0m, in \u001b[0;36mMinio._get_region\u001b[0;34m(self, bucket_name)\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m region\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# Execute GetBucketLocation REST API to get region of the bucket.\u001b[39;00m\n\u001b[0;32m--> 494\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_url_open\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mus-east-1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbucket_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbucket_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m element \u001b[38;5;241m=\u001b[39m ET\u001b[38;5;241m.\u001b[39mfromstring(response\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdecode())\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m element\u001b[38;5;241m.\u001b[39mtext:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/redbox-MiicHf1r-py3.11/lib/python3.11/site-packages/minio/api.py:302\u001b[0m, in \u001b[0;36mMinio._url_open\u001b[0;34m(self, method, region, bucket_name, object_name, body, headers, query_params, preload_content, no_body_trace)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    300\u001b[0m         http_headers\u001b[38;5;241m.\u001b[39madd(key, value)\n\u001b[0;32m--> 302\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_http\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43murlunsplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace_stream:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace_stream\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHTTP/1.1 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/redbox-MiicHf1r-py3.11/lib/python3.11/site-packages/urllib3/poolmanager.py:444\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    442\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/redbox-MiicHf1r-py3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:877\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[1;32m    874\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    875\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[1;32m    876\u001b[0m     )\n\u001b[0;32m--> 877\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[1;32m    896\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/redbox-MiicHf1r-py3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:877\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[1;32m    874\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    875\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[1;32m    876\u001b[0m     )\n\u001b[0;32m--> 877\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[1;32m    896\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "    \u001b[0;31m[... skipping similar frames: HTTPConnectionPool.urlopen at line 877 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/redbox-MiicHf1r-py3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:877\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[1;32m    874\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    875\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[1;32m    876\u001b[0m     )\n\u001b[0;32m--> 877\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[1;32m    896\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/redbox-MiicHf1r-py3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:847\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_e, (\u001b[38;5;167;01mOSError\u001b[39;00m, HTTPException)):\n\u001b[1;32m    845\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 847\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    850\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n\u001b[1;32m    852\u001b[0m \u001b[38;5;66;03m# Keep track of the error for the retry warning.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/redbox-MiicHf1r-py3.11/lib/python3.11/site-packages/urllib3/util/retry.py:515\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[1;32m    514\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    517\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_retry\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: /redbox-storage-dev?location= (Caused by ProtocolError('Connection aborted.', BadStatusLine('ÿ\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x7fo\\x01t: localhost:9000\\r\\n')))"
     ]
    }
   ],
   "source": [
    "# This loads to redbox-storage-dev/data_eval/Universal-Basic-Income-Scotland-Report.pdf\n",
    "# Is the 'data_eval' part of the path going to be a problem?\n",
    "upload_to_minio(\"Universal-Basic-Income-Scotland-Report.pdf\", \"redbox-storage-dev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a note of this file name. If it differs from `redbox-storage-dev/data_eval/Universal-Basic-Income-Scotland-Report.pdf`you will need up update the file name passed to the `ingest` function in the chunking playground section below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = \"redbox-storage-dev/data_eval/Universal-Basic-Income-Scotland-Report.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking Playground\n",
    "\n",
    "Please experiment with different chunking strategies to see if the retrieval evalatuion metrics can be improved. **For MVP focus on `other_chunker`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document Chunking\n",
    "\n",
    "Redbox currently has two types of chunking methods:\n",
    "- `chunk_clustering`  | located in: redbox/parsing/chunk_clustering.py\n",
    "- `other_chunker`     | located in: redbox/parsing/chunkers.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [2024-05-14] Chunk Clustering steer for MVP\n",
    "Chunk clustering stage (maybe we should call it agglomeration for accuracy?) currently takes a significant amount of processing in the upload phase of the user journey. Given we have limited capacity for evaluating the benefit it is bringing whilst we bring our benchmarks online we will disable the chunk clustering phase in the short term. \n",
    "\n",
    "This is with the view of reinstating further down the line and potentially exploring enhancements post MVP. These enhancements could be the recursive clustering idea or factoring document structure into the current algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps for follow\n",
    "1. Create a git branch off of `main`\n",
    "2. Make edits directly in the [Redbox parsing file](../../redbox/parsing/chunkers.py), within the `other_chunker` function\n",
    "3. Follow the imports below and then continue with the rest of the notebook to get retrieval evaluation scores\n",
    "\n",
    "**NOTE** If you make continue to make changes to the `other_chunkers` function, ensure you have run the `%autoreload` cell, for updates to be automatically reloaded into the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Add %autoreload cell for imported parsing functions to be reloaded if they are changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports from worker/src/app.py\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# from fastapi import Depends, FastAPI\n",
    "# from faststream.redis.fastapi import RedisRouter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional functions imported from worker/src/app.py\n",
    "from worker.src.app import get_storage_handler, get_chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Do we need to set a flag to ensure other_chunker is used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from minio import Minio\n",
    "# from minio.error import S3Error\n",
    "\n",
    "# def get_from_minio(file_path, bucket_name):\n",
    "#     # Create a client with the MinIO server, its access key and secret key.\n",
    "#     client = Minio(\"localhost:9000\", access_key=\"minioadmin\", secret_key=\"minioadmin\", secure=False)\n",
    "\n",
    "#     try:\n",
    "#         # Check if 'bucket_name' exists.\n",
    "#         if client.bucket_exists(bucket_name):\n",
    "#             # Get 'file_path' from bucket 'bucket_name'.\n",
    "#             data = client.get_object(bucket_name, file_path)\n",
    "#             # Read the first kilobyte of data and print it\n",
    "#             print(data.read(1024))\n",
    "#         else:\n",
    "#             print(f'Bucket {bucket_name} does not exist')\n",
    "\n",
    "#     except S3Error as exc:\n",
    "#         print(f'error occurred: {exc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Minio(\"localhost:9000\", access_key=\"minioadmin\", secret_key=\"minioadmin\", secure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest(\n",
    "    file: File,\n",
    "    storage_handler: ElasticsearchStorageHandler,\n",
    "    chunker: FileChunker\n",
    "):\n",
    "    \"\"\"\n",
    "    1. Chunks file\n",
    "    2. Puts chunks to ES\n",
    "    3. Acknowledges message\n",
    "    4. Puts chunk on embedder-queue\n",
    "    \"\"\"\n",
    "\n",
    "    logging.info(\"Ingesting file: %s\", file)\n",
    "\n",
    "    chunks = chunker.chunk_file(file=file)\n",
    "\n",
    "    logging.info(\"Writing %s chunks to storage for file uuid: %s\", len(chunks), file.uuid)\n",
    "\n",
    "    items = storage_handler.write_items(chunks)\n",
    "    logging.info(\"written %s chunks to elasticsearch\", len(items))\n",
    "\n",
    "    return items\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a File\n",
    "file = File(key='data_eval/Universal-Basic-Income-Scotland-Report.pdf', bucket='redbox-storage-dev', creator_user_uuid='123e4567-e89b-12d3-a456-426614174000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the ingest function\n",
    "items = ingest(file, storage_handler, chunker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# Initialize the Elasticsearch client\n",
    "es = Elasticsearch(\n",
    "                hosts=[\n",
    "                    {\n",
    "                        \"host\": \"localhost\",\n",
    "                        \"port\": 9200,\n",
    "                        \"scheme\": \"http\",\n",
    "                    }\n",
    "                ],\n",
    "                basic_auth=(\"elastic\", \"redboxpass\"),\n",
    "            )\n",
    "\n",
    "# Define the search query\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"match_all\": {}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Execute the search query\n",
    "response = es.search(index=\"redbox-data-chunk\", body=query)\n",
    "\n",
    "# Print the search results\n",
    "for hit in response['hits']['hits']:\n",
    "    print(hit['_source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# Initialize the Elasticsearch client\n",
    "es = Elasticsearch(\n",
    "    hosts=[\n",
    "        {\n",
    "            \"host\": \"localhost\",\n",
    "            \"port\": 9200,\n",
    "            \"scheme\": \"http\",\n",
    "        }\n",
    "    ],\n",
    "    basic_auth=(\"elastic\", \"redboxpass\"),\n",
    ")\n",
    "\n",
    "# Define the search query\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"match_all\": {}\n",
    "    },\n",
    "    \"size\": 10000  # Increase this number to return more documents\n",
    "}\n",
    "\n",
    "# Execute the search query\n",
    "response = es.search(index=\"redbox-data-chunk\", body=query)\n",
    "\n",
    "# Print the search results\n",
    "for hit in response['hits']['hits']:\n",
    "    print(hit['_source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from minio import Minio\n",
    "# from minio.error import S3Error\n",
    "\n",
    "# def get_from_minio(file_path, bucket_name):\n",
    "#     # Create a client with the MinIO server, its access key and secret key.\n",
    "#     client = Minio(\"localhost:9000\", access_key=\"minioadmin\", secret_key=\"minioadmin\", secure=False)\n",
    "\n",
    "#     try:\n",
    "#         # Check if 'bucket_name' exists.\n",
    "#         if client.bucket_exists(bucket_name):\n",
    "#             # Get 'file_path' from bucket 'bucket_name'.\n",
    "#             data = client.get_object(bucket_name, file_path)\n",
    "#             # Read the first kilobyte of data and print it\n",
    "#             print(data.read(1024))\n",
    "#         else:\n",
    "#             print(f'Bucket {bucket_name} does not exist')\n",
    "\n",
    "#     except S3Error as exc:\n",
    "#         print(f'error occurred: {exc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Playground <a class=\"anchor\" id=\"five-section\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do an initial run through this notebook with the starting/default prompts BEFORE your first experiment.** This will give you baseline scores for each metric to compare your experiment results against.\n",
    "\n",
    "Add baseline scores below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Baseline evaluation\n",
    "\n",
    "**[2024-05-15] Baseline scores**\n",
    "Using the deployed /chat/rag enpoint to get `actual_output` from Redbox RAG chat, we got the following baseline scores for each metric:\n",
    "- Faithfulness: **#TODO: Populate after first run through**\n",
    "- Answer Relevancy: **#TODO: Populate after first run through**\n",
    "- Hallucination: **#TODO: Populate after first run through**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have done your first run through the notebook, please experiment with these prompts as you see fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to experiment with:\n",
    "1. `_core_redbox_prompt`\n",
    "2. `CORE_REDBOX_PROMPT`\n",
    "3. `_with_sources_template`\n",
    "4. `WITH_SOURCES_PROMPT`\n",
    "5. `_stuff_document_template`\n",
    "6. `STUFF_DOCUMENT_PROMPT`\n",
    "7. The LLM being used - **For now, please stick with gpt-3.5-turbo, as we establish a baseline quality**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refining Question Prompts\n",
    "This refining of the question is pre-retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_chat_template = \"\"\"Given the following conversation and a follow up question,\n",
    "rephrase the follow up question to be a standalone question, in its original\n",
    "language. include the follow up instructions in the standalone question.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_chat_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAG prompts  <a class=\"anchor\" id=\"six-section\"></a>\n",
    "These are the prompts that will have most effect on RAG generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_core_redbox_prompt = \"\"\"You are RedBox Copilot. An AI focused on helping UK Civil Servants, Political Advisors and\\\n",
    "Ministers triage and summarise information from a wide variety of sources. You are impartial and\\\n",
    "non-partisan. You are not a replacement for human judgement, but you can help humans\\\n",
    "make more informed decisions. If you are asked a question you cannot answer based on your following instructions, you\\\n",
    "should say so. Be concise and professional in your responses. Respond in markdown format.\n",
    "\n",
    "=== RULES ===\n",
    "\n",
    "All responses to Tasks **MUST** be translated into the user's preferred language.\\\n",
    "This is so that the user can understand your responses.\\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check where CORE_REDBOX_PROMPT is used in the codebase\n",
    "CORE_REDBOX_PROMPT = PromptTemplate.from_template(_core_redbox_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_with_sources_template = \"\"\"Given the following extracted parts of a long document and \\\n",
    "a question, create a final answer with Sources at the end.  \\\n",
    "If you don't know the answer, just say that you don't know. Don't try to make \\\n",
    "up an answer.\n",
    "Be concise in your response and summarise where appropriate. \\\n",
    "At the end of your response add a \"Sources:\" section with the documents you used. \\\n",
    "DO NOT reference the source documents in your response. Only cite at the end. \\\n",
    "ONLY PUT CITED DOCUMENTS IN THE \"Sources:\" SECTION AND NO WHERE ELSE IN YOUR RESPONSE. \\\n",
    "IT IS CRUCIAL that citations only happens in the \"Sources:\" section. \\\n",
    "This format should be <DocX> where X is the document UUID being cited.  \\\n",
    "DO NOT INCLUDE ANY DOCUMENTS IN THE \"Sources:\" THAT YOU DID NOT USE IN YOUR RESPONSE. \\\n",
    "YOU MUST CITE USING THE <DocX> FORMAT. NO OTHER FORMAT WILL BE ACCEPTED.\n",
    "Example: \"Sources: <DocX> <DocY> <DocZ>\"\n",
    "\n",
    "Use **bold** to highlight the most question relevant parts in your response.\n",
    "If dealing dealing with lots of data return it in markdown table format.\n",
    "\n",
    "QUESTION: {question}\n",
    "=========\n",
    "{summaries}\n",
    "=========\n",
    "FINAL ANSWER:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WITH_SOURCES_PROMPT = PromptTemplate.from_template(_core_redbox_prompt + _with_sources_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_stuff_document_template = \"<Doc{parent_doc_uuid}>{page_content}</Doc{parent_doc_uuid}>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STUFF_DOCUMENT_PROMPT = PromptTemplate.from_template(_stuff_document_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you find changes to the prompts above improve the generation evaluation scores, please consider making a PR to update the code in main.\n",
    "\n",
    "All these prompts are locations in [chat.py](../../redbox/llm/prompts/chat.py), except `_core_redbox_prompt` which is located in [core.py](../../redbox/llm/prompts/core.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain_elasticsearch import ApproxRetrievalStrategy, ElasticsearchStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info(\"Loading embedding model from environment: %s\", env.embedding_model)\n",
    "embedding_model = SentenceTransformerEmbeddings(model_name=env.embedding_model)\n",
    "log.info(\"Loaded embedding model from environment: %s\", env.embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Model cacching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if env.elastic.subscription_level == \"basic\":\n",
    "    strategy = ApproxRetrievalStrategy(hybrid=False)\n",
    "elif env.elastic.subscription_level in [\"platinum\", \"enterprise\"]:\n",
    "    strategy = ApproxRetrievalStrategy(hybrid=True)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown Elastic subscription level {env.elastic.subscription_level}\")\n",
    "\n",
    "\n",
    "vector_store = ElasticsearchStore(\n",
    "    es_connection=es,\n",
    "    index_name=\"redbox-data-chunk\",\n",
    "    embedding=embedding_model,\n",
    "    strategy=strategy,\n",
    "    vector_query_field=\"embedding\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate RAG responses and append them to evaluation dataset  <a class=\"anchor\" id=\"seven-section\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#TODO: Load required functions\n",
    "\n",
    "#TODO: Any functions below that we need to mock?\n",
    "\n",
    "# I would like to keep the rag_chat function unchanged from what it is in the core_api repo.\n",
    "\n",
    "# However, the user_uuid is only used for authorisation (it is NOT used for authentication), so if too troublesome, can be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create `ChatRequest` for evaluation dataset, used by the RAG chat function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the `ChatRequest` Pydantic model used by the RAG chat function, the JSON body should contain a `message_history` key with a list of chat messages.\n",
    "\n",
    "Each chat message should match the structure defined by the `ChatMessage` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_request = {\n",
    "                \"message_history\": [\n",
    "                        {\"text\": \"You are a helpful AI Assistant\", \"role\": \"system\"},\n",
    "                        {\"text\": \"What is Universal Basic Income?\", \"role\": \"user\"},\n",
    "                ]\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This only works within the function (or FastAPI), due to attribute access: question = chat_request.message_history[-1].text\n",
    "question = chat_request[\"message_history\"][-1]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RAG chat function - generation part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LLM setup ===\n",
    "llm = ChatLiteLLM(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    streaming=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rag_chat(chat_request: ChatRequest, user_uuid: Annotated[UUID, Depends(get_user_uuid)]) -> ChatResponse:\n",
    "def rag_chat(chat_request, user_uuid) -> ChatResponse:    \n",
    "    \"\"\"Get a LLM response to a question history and file\n",
    "\n",
    "    Args:\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        StreamingResponse: a stream of the chain response\n",
    "    \"\"\"\n",
    "    question = chat_request[\"message_history\"][-1][\"text\"]\n",
    "    previous_history = list(chat_request[\"message_history\"][:-1])\n",
    "    previous_history = ChatPromptTemplate.from_messages(\n",
    "        (msg[\"role\"], msg[\"text\"]) for msg in previous_history\n",
    "    ).format_messages()\n",
    "\n",
    "    condense_question_chain = LLMChain(llm=llm, prompt=CONDENSE_QUESTION_PROMPT)\n",
    "\n",
    "    standalone_question = condense_question_chain({\"question\": question, \"chat_history\": previous_history})[\"text\"]\n",
    "\n",
    "    docs = vector_store.as_retriever(\n",
    "        search_kwargs={\"filter\": {\"term\": {\"creator_user_uuid.keyword\": str(user_uuid)}}}\n",
    "    ).get_relevant_documents(standalone_question)\n",
    "\n",
    "    docs_with_sources_chain = load_qa_with_sources_chain(\n",
    "        llm,\n",
    "        chain_type=\"stuff\",\n",
    "        prompt=WITH_SOURCES_PROMPT,\n",
    "        document_prompt=STUFF_DOCUMENT_PROMPT,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    result = docs_with_sources_chain(\n",
    "        {\n",
    "            \"question\": standalone_question,\n",
    "            \"input_documents\": docs,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    source_documents = [\n",
    "        SourceDocument(\n",
    "            page_content=langchain_document.page_content,\n",
    "            file_uuid=langchain_document.metadata.get(\"parent_doc_uuid\"),\n",
    "            page_numbers=langchain_document.metadata.get(\"page_numbers\"),\n",
    "        )\n",
    "        for langchain_document in result.get(\"input_documents\", [])\n",
    "    ]\n",
    "    return ChatResponse(output_text=result[\"output_text\"], source_documents=source_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate `actual_output` using RAG and evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: This is where we put it all together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = rag_chat(chat_request, 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Append `actual_output` to evaluation dataset\n",
    "Process the goldens and convert them into test cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A hypothetical LLM application example\n",
    "from chatbot import query\n",
    "from typing import List\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.dataset import Golden\n",
    "...\n",
    "\n",
    "def convert_goldens_to_test_cases(goldens: List[Golden]) -> List[LLMTestCase]:\n",
    "    test_cases = []\n",
    "    for golden in goldens:\n",
    "        test_case = LLMTestCase(\n",
    "            input=golden.input,\n",
    "            # Generate actual output using the 'input' and 'additional_metadata'\n",
    "            actual_output = rag_chat(chat_request: ChatRequest, user_uuid=1234)\n",
    "            actual_output = rag_chat\n",
    "            actual_output=query(golden.input, golden.additional_metadata),\n",
    "            expected_output=golden.expected_output,\n",
    "            context=golden.context,\n",
    "        )\n",
    "        test_cases.append(test_case)\n",
    "    return test_cases\n",
    "\n",
    "# Data preprocessing before setting the dataset test cases\n",
    "dataset.test_cases = convert_goldens_to_test_cases(dataset.goldens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run generation evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics import AnswerRelevancyMetric\n",
    "from deepeval.test_case import LLMTestCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Promote optimised prompts into production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you find changes to the prompts above improve the generation evaluation scores, please consider making a PR to update the code in `core_api`. Follow these steps:\n",
    "\n",
    "1. Create a new branch off `main`\n",
    "2. Make changes in the locations listed below\n",
    "3. Run through the e2e RAG evaluation notebook\n",
    "4. If e2e RAG evaluation metrics are improved, please make a PR!\n",
    "\n",
    "All these prompts are locations in [chat.py](../../redbox/llm/prompts/chat.py), except `_core_redbox_prompt` which is located in [core.py](../../redbox/llm/prompts/core.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redbox-MiicHf1r-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
