input,context,expected_output,actual_output
How can researchers and science funders address harmful polarisation in political debate through encouraging engagement across scientific disciplines?,"['ndings may also lead to a general scepticism about the rigour of scientiﬁc evidence being invoked.\n\n20\n\nPublic trust in science-for-policymaking\n\nThe risk of such polarisation implies the need for researchers and knowledge brokers to better integrate diﬀerent approaches and methods, to avoid this silo eﬀect when the evidence is subsequently invoked in policy debate. Interdisciplinary collaboration and evidence syntheses can encourage better engagement across disciplines, contributing to more integrated use of diﬀerent scientiﬁc ﬁndings in policy debate, as well as being a way to work through the issues around framing, as discussed in Condition 1.1. One historic example of this is the emergence in the 1980s of the ‘ecomodernist’ frame which led to the move from sectoral control of serious pollutants to Integrated Pollution Control where the environment is treated more holistically. The shift took integrated pollution control from a bureaucratic approach to a focus on ‘eﬃciency savings’ and was achieved through integrating scientiﬁc evidence with experience, values and interests supported by evidence from the social sciences and humanities (Owens, 2015). The IPCC (Intergovernmental Panel on Climate Change) process also illustrates this point about integrated evidence bases well, providing a mechanism for drawing together multiple types of scientiﬁc evidence in a relatively open, peer-reviewed process, giving it signiﬁcant political weight (De Pryck, 2021; Hulme and de Pryck, 2022).\n\nImplications for policymaking and science advice\n\nTrust in scientiﬁc sources. Policymakers and science communicators should be\n\naware of different levels of trust in scientific sources. This will depend in part on the policy area. For example, the commissioned survey research found that on issues with location-specific implications (such as clean air zones), local scientific work elicited greater support than evidence emerging from overseas science bodies. This is consistent with wider findings showing the importance of local knowledge systems. By contrast, industry-funded sources of knowledge may be less trusted because of public scepticism about corporate interests driving debate – indeed, surveys suggest that publics are more willing to trust scientific sources that are seen as ‘independent’.\n\nCitizen engagement. Public engagement in science-for-policymaking has the potential to generate greater levels of public trust. However, the effects are context-dependent and there is a need for nuanced analysis and systematic evaluation. While the project’s case study research found evidence that research involving citizen engagement could at times generate greater levels of public trust, a recent review of public engagement for Defra found that the effects of engagement on public trust are highly contextual (Defra Social Science Expert Group, 2022).\n\n\n\nScience and polarisation. The evidence considered also identified cases where distinct scientific fields (and findings) were marshalled by different protagonists selectively, to support diverging views (Owens, 2015). This may increase harmful polarisation, with participants speaking ‘past’ one another rather than engaging in constructive dialogue. Researchers and science funders can play a role in addressing this, through encouraging engagement across scientific disciplines, so that evidence from different disciplines is integrated rather than siloed – for example through comprehensive evidence reviews and syntheses.\n\nDimension 3: How science-for-policymaking is communicated\n\nThe third dimension focuses on how science is invoked and communicated in political debate. The project ﬁndings highlight the importance of being transparent about the uncertainty of science, with members of the public often expecting, and readily accommodating, such uncertainty. Evidence also points to the importance of familiarity and having a stake in local issues as a basis for building trust (Giddens, 1994). Finally, our ﬁndings point to how styles of communication, including the presentation of data and the use of visualisation can inﬂuence trust in science-for-policymaking.\n\n21\n\nPublic trust in science-for-policymaking\n\nCondition 3.1: Acknowledging uncertainty\n\nA common misconception is that scientiﬁc uncertainty will contribute to mistrust in science (Kerr et al., 2022).10 It is often assumed that exposure to scientiﬁc ﬁndings that are not settled or deﬁnitive will encourage scepticism amongst publics. However, literature on social understanding of science has shown that people can be ‘reﬂexive’ about science: that is, they recognise contingency and accept that new ﬁndings may be fallible, and superseded by new evidence or shifts in scientiﬁc paradigms (Giddens, 1994). Partly because of this ‘reﬂexive turn’,']","Researchers and science funders can address harmful polarisation in political debate by encouraging engagement across scientific disciplines. This can be achieved through comprehensive evidence reviews and syntheses, ensuring that evidence from different disciplines is integrated rather than siloed. By promoting collaboration and integration of diverse scientific perspectives, they can prevent the selective marshalling of scientific fields and findings to support diverging views, ultimately fostering constructive dialogue and reducing harmful polarisation.",
How does research and innovation funding impact different UK regions?,"['�, distributing 69% of its impact to other regions. This finding is particularly relevant for the ‘levelling up’ discussion, where many metrics typically used to explore research and innovation (R&I) focus on input measures (e.g. the research investment location). As this impact analysis shows, examining which institutions receive funding provides a partial picture of the role R&I plays across UK regions.\n\niii\n\n0101: Pure Mathematics\n\n0102: Applied Mathematics\n\n0103: Numerical and Computational Mathematics\n\n0104: Statistics\n\n0105: Mathematical Physics\n\n0199: Other Mathematical Sciences\n\n0201: Astronomical and Space Sciences\n\n0202: Atomic, Molecular, Nuclear, Particle and Plasma Physics\n\n0203: Classical Physics\n\n0204: Condensed Matter Physics\n\n0205: Optical Physics\n\n0206: Quantum Physics\n\n1: Public Health and Health Services\n\n0299: Other Physical Sciences\n\n0301: Analytical Chemistry\n\n0: Public health\n\n0302: Inorganic Chemistry\n\n16: NHS\n\n0303: Macromolecular and Materials Chemistry\n\n26: Dentistry\n\n0304: Medicinal and Biomolecular Chemistry\n\n38: Sexually transmitted infections and HIV\n\n0305: Organic Chemistry\n\n40: Dementia and Alzheimer’s\n\n0306: Physical Chemistry (Incl. Structural)\n\n0307: Theoretical and Computational Chemistry\n\n44: Mental health\n\n0399: Other Chemical Sciences\n\n0401: Atmospheric Sciences\n\n60: Social services and primary care\n\n0402: Geochemistry\n\n0403: Geology\n\n0404: Geophysics\n\n2: Clinical Medicine\n\n0405: Oceanography\n\n0406: Physical Geography and Environmental Geoscience\n\n1: Treatment and disease\n\n0499: Other Earth Sciences\n\n0501: Ecological Applications\n\n0502: Environmental Science and Management\n\n10: Cancer diagnostics and therapy\n\n0503: Soil Sciences\n\n0599: Other Environmental Sciences\n\n20: Drug discovery and clinical trials\n\nUoA 1: Clinical Medicine\n\n0601: Biochemistry and Cell Biology\n\n28: Viruses and vaccination\n\n0602: Ecology\n\n29: Stroke and brain injury\n\n0603: Evolutionary Biology\n\n45: Genetic testing and diagnostics\n\n0604: Genetics\n\n0605: Microbiology\n\n58: Diabetes\n\nUoA 2: Public Health, Health Servicesand Primary Care\n\n0606: Physiology\n\n71: Health screening and preventative treatment\n\n0607: Plant Biology\n\n0608: Zoology\n\n76: Infectious disease\n\nUoA 3: Allied Health Professions, Dentistry, Nursing and Pharmacy\n\n0699: Other Biological Sciences\n\n0701: Agriculture, Land and Farm Management\n\n0702: Animal Production\n\n3: Energy, Environment and Engineering\n\n0703: Crop and Pasture Production\n\n11: Climate change\n\n0704: Fisheries Sciences\n\n0705: Forestry Sciences\n\n30: Pollution and air quality\n\n0706: Horticultural Production\n\nUoA 4: Psychology, Psychiatry and Neuroscience\n\n0707: Veterinary Sciences\n\n42: Energy\n\n0799: Other Agricultural and Veterinary Sciences\n\n51: Nuclear energy and research\n\n0801: Artificial Intelligence and Image Processing\n\n55: Environmental sustainability\n\n0802: Computation Theory and Mathematics\n\n0803: Computer Software\n\n70: Engineering\n\n0804: Data Format\n\nUoA 5: Biological Sciences\n\n0805: Distributed Computing\n\n74: Manufacturing and emissions\n\n0806: Information Systems\n\n0807: Library and Information Studies\n\n4: Information, Applied Technology and Analytics\n\nUoA 6: Agriculture, Food and Veterinary Sciences\n\n0899: Other Information and Computing Sciences\n\n0901: Aerospace Engineering\n\n2: Computing and software development\n\n0902: Automotive Engineering\n\n0903: Biomedical Engineering\n\nUoA 7: Earth Systems and Environmental Sciences\n\n3: Applied technology\n\n0904: Chemical Engineering\n\n0905: Civil Engineering\n\n39: Computer science and data analysis\n\nUoA 8: Chemistry\n\n0906: Electrical and Electronic Engineering\n\n57: Safety and risk management\n\n0907: Environmental Engineering\n\nUoA 9: Physics\n\n0908: Food Sciences\n\n0909: Geomatic Engineering\n\n5: Training, Education and Skills\n\n0910: Manufacturing Engineering\n\n0911: Maritime Engineering\n\nUoA 10: Mathematical Sciences\n\n0912: Materials']","Research and innovation funding impact different UK regions by distributing 69% of its impact to other regions. This finding is particularly relevant for the ‘levelling up’ discussion, where many metrics typically used to explore research and innovation (R&I) focus on input measures (e.g. the research investment location). Examining which institutions receive funding provides a partial picture of the role R&I plays across UK regions.",
How are research outputs classified and grouped by discipline using the ANZSRC classification system?,"[', illustrating that impact was often a bespoke activity. Given these impact pathways’ diversity, developing a balanced and comprehensive set of impact metrics that capture this range of activities would be challenging. The results demonstrate the numerous, complex and often unique impact pathways involved.\n\n21\n\nKing’s College London and Digital Science (2015).\n\n22\n\nFoR codes are a classification system managed by the Australia and New Zealand Classification (ANZSRC) to group research, researchers and their outputs by discipline. They are commonly used in bibliometric analyses to classify research outputs’ disciplines, and can be applied at three nested levels reflecting the classification’s granularity: six- digit codes (the most granular), four-digit codes and two-digit codes (the least granular). We used four-digit codes in this analysis.\n\n15\n\n0101: Pure Mathematics\n\n0102: Applied Mathematics\n\n0103: Numerical and Computational Mathematics\n\n0104: Statistics\n\n0105: Mathematical Physics\n\n0199: Other Mathematical Sciences\n\n0201: Astronomical and Space Sciences\n\n0202: Atomic, Molecular, Nuclear, Particle and Plasma Physics\n\n0203: Classical Physics\n\n0204: Condensed Matter Physics\n\n0205: Optical Physics\n\n0206: Quantum Physics\n\n1: Public Health and Health Services\n\n0299: Other Physical Sciences\n\n0301: Analytical Chemistry\n\n0: Public health\n\n0302: Inorganic Chemistry\n\n16: NHS\n\n0303: Macromolecular and Materials Chemistry\n\n26: Dentistry\n\n0304: Medicinal and Biomolecular Chemistry\n\n38: Sexually transmitted infections and HIV\n\n0305: Organic Chemistry\n\n40: Dementia and Alzheimer’s\n\n0306: Physical Chemistry (Incl. Structural)\n\n0307: Theoretical and Computational Chemistry\n\n44: Mental health\n\n0399: Other Chemical Sciences\n\n0401: Atmospheric Sciences\n\n60: Social services and primary care\n\n0402: Geochemistry\n\n0403: Geology\n\n0404: Geophysics\n\n2: Clinical Medicine\n\n0405: Oceanography\n\n0406: Physical Geography and Environmental Geoscience\n\n1: Treatment and disease\n\n0499: Other Earth Sciences\n\n0501: Ecological Applications\n\n0502: Environmental Science and Management\n\n10: Cancer diagnostics and therapy\n\n0503: Soil Sciences\n\n0599: Other Environmental Sciences\n\n20: Drug discovery and clinical trials\n\nUoA 1: Clinical Medicine\n\n0601: Biochemistry and Cell Biology\n\n28: Viruses and vaccination\n\n0602: Ecology\n\n29: Stroke and brain injury\n\n0603: Evolutionary Biology\n\n45: Genetic testing and diagnostics\n\n0604: Genetics\n\n0605: Microbiology\n\n58: Diabetes\n\nUoA 2: Public Health, Health Servicesand Primary Care\n\n0606: Physiology\n\n71: Health screening and preventative treatment\n\n0607: Plant Biology\n\n0608: Zoology\n\n76: Infectious disease\n\nUoA 3: Allied Health Professions, Dentistry, Nursing and Pharmacy\n\n0699: Other Biological Sciences\n\n0701: Agriculture, Land and Farm Management\n\n0702: Animal Production\n\n3: Energy, Environment and Engineering\n\n0703: Crop and Pasture Production\n\n11: Climate change\n\n0704: Fisheries Sciences\n\n0705: Forestry Sciences\n\n30: Pollution and air quality\n\n0706: Horticultural Production\n\nUoA 4: Psychology, Psychiatry and Neuroscience\n\n0707: Veterinary Sciences\n\n42: Energy\n\n0799: Other Agricultural and Veterinary Sciences\n\n51: Nuclear energy and research\n\n0801: Artificial Intelligence and Image Processing\n\n55: Environmental sustainability\n\n0802: Computation Theory and Mathematics\n\n0803: Computer Software\n\n70: Engineering\n\n0804: Data Format\n\nUoA 5: Biological Sciences\n\n0805: Distributed Computing\n\n74: Manufacturing and emissions\n\n0806: Information Systems\n\n0807: Library and Information Studies\n\n4: Information, Applied Technology and Analytics\n\nUoA 6: Agriculture, Food and Veterinary Sciences\n\n0899: Other Information and Computing Sciences\n\n0901: Aerospace Engineering\n\n2: Computing and software development\n\n0902: Automotive Engineering\n\n0903: Biomedical Engineering\n\nUoA 7: Earth Systems and Environmental Sciences\n\n3: Applied technology\n\n0904: Chemical Engineering\n\n0905: Civil Engineering\n\n39: Computer science and data analysis\n\n']","Research outputs are classified and grouped by discipline using the ANZSRC classification system through FoR codes, which are a classification system managed by the Australia and New Zealand Classification (ANZSRC). These codes can be applied at three nested levels - six-digit codes, four-digit codes, and two-digit codes, with four-digit codes being used in this analysis to classify research outputs' disciplines.",
How does public engagement with science influence public perspectives on the relevance and trustworthiness of science in policymaking?,"['\na.\n\nThe issue is contested in public debate, implying it is the object of party political and/or interest group contestation and media coverage (including social media).\n\nb.\n\nScience is considered as relevant to informing this contested debate, implying that it is deemed helpful in shaping policy responses – even if it is not necessarily invoked by all participants in the debate, or it is invoked in a tokenistic way.\n\n10\n\nPublic engagement with science Science\n\nScience advice\n\nPolitical comms\n\nScience policy\n\nScience comms\n\nPublicsPolicy\n\nPublic opinion\n\n11\n\nPublic trust in science-for-policymaking\n\nIt is in these contexts that it becomes particularly important to ensure that scientiﬁc advice is a relevant and trustworthy resource for guiding policymaking – noting, of course, that science will be just one input into public deliberation, alongside other forms of knowledge, values and interests.\n\nDeﬁnitions\n\nThe report focuses on the three-way relationship between science, publics, and policy (see Figure 1) that comprise the science-for-policymaking system.\n\nScience: Policymakers draw on\n\n\n\nPolicy science to inform their decisions (science advice), and also shape science through regulation and funding (science policy).\n\nPublics: Policymakers Policy communicate how they have used science to their voters, or publics (political communication), and they are guided by the public in how they prioritise and take decisions on policy issues (public opinion).\n\n\n\nScience: Publics engage Publics with science through the media and other forms of engagement (science communication), and they also feed into scientific research and findings through various mechanisms including citizen science and consultation (public engagement with science).\n\n\n\nFigure 1: Simplified graphic illustrating the relationships between science, publics and policy.\n\nThis (inevitably simplified) schema helps define the focus of this report. We are most concerned with how the use of science-for-policymaking, political communication, science communication, and public engagement with science, influence public perspectives on the relevance and trustworthiness of science.\n\nWe also need to be clear about how we are using key terms in the report.\n\nScience is used in a broad sense to describe research drawn from across all disciplines. Science involves the production of new knowledge using validated processes and methods.\n\nScience-for-policymaking is shorthand for the set of methods, insights and findings produced by researchers that are invoked as (potentially) relevant to policymaking.5\n\nThe report uses this term to highlight the focus on science that is used in policymaking as opposed to science that has other purposes. We also refer to the science-for-policymaking community which comprises the researchers, science communicators, knowledge brokers, public servants and science funders who have a role in enabling, producing, communicating and deploying science-for-policymakers.\n\nPolicymakers refers to those directly involved in formulating policy. Within this group, we can distinguish between elected representatives (in the legislature and in government), whom we refer to as ‘politicians’; and civil servants and senior advisors (scientific or otherwise), whom we refer to as ‘officials’. Each of these groupings will use evidence, but they may invoke it or consider it at different stages or in different ways, and so attention to this nuance in who is using evidence in the science-for-policymaking system, and when, is important. We try to carefully distinguish which type of policymaker we are referring to throughout this report.\n\nPublic trust in science-for-policymaking\n\n12\n\nPublic policy denotes the ideas, plans and programmes advanced by government to address societal challenges, which are adopted and implemented as collectively binding decisions.\n\nThe report uses the term policymaking or the policy process or cycle to indicate three stages of this process: issue definition, debate and decision, and implementation. Meanwhile, politics and political debate are understood as the process through which political parties and interested parties (including scientists, but other actors as well) mobilise public support for different policies.\n\nPublics refers to the plurality of groups of people with varying levels of interest and involvement in an issue. There is no singular ‘public’; rather, there are many different groupings, some stable, some shifting. Publics have become more fragmented and ways of engaging with them have multiplied (Defra Social Science Expert Group, 2022), making it important to differentiate specific ‘publics’ rather than treating people as a homogenous group. The adjective, public, is still used in the report to distinguish activities that concern or affect publics, such as public health.\n\nTrust can be defined as a willingness to endow authority or responsibility in others to act on our behalf (Shapiro,']","Public engagement with science influences public perspectives on the relevance and trustworthiness of science in policymaking by providing opportunities for the public to interact with scientific information, contribute to research, and understand the implications of scientific findings. This engagement helps build trust in the scientific process and its role in informing policy decisions, shaping public opinion, and guiding policymakers.",
How can policymakers maintain the authority of science in policy-making while balancing scientific evidence with other factors and preserving public trust?,"[' example of this is the case of genetic modiﬁcation. Supporters and critics both invoke science, but each side is invoking their ‘preferred’ scientiﬁc ﬁndings, linked to a distinct set of values. It is important to note that this applies across stakeholder groups, including policymakers, researchers and diﬀerent coaltions of interests when ﬁndings from diﬀerent types of science challenge various positions and commitments. Over time, these frames and patterns of contestation become familiar and entrenched, leading to an impasse in debate.\n\nIn sum, the ﬁndings suggest that contestation in public debate does not have a consistent eﬀect: it may distract from science, or it may amplify and polarise competing scientiﬁc evidence, with science being marshalled in a highly selective way. The following box draws out some of the key implications of the ﬁndings discussed under this ﬁrst dimension.\n\n18\n\nPublic trust in science-for-policymaking\n\nImplications for science advice and policymaking:\n\n\n\nFraming and science-for-policymaking. Policymakers play an important role in ‘framing’ policy issues: determining which dimensions of an issue are foregrounded and which are regarded as less central, as well as how they are linked to potential policy solutions. Framing will influence how far scientific evidence is seen as relevant to policy deliberation. This means that policymakers can be instrumental in influencing the extent to which relevant, robust scientific findings are invoked in political debate.\n\nWindows of opportunity. Policymakers have most influence in shaping these frames early on in the process of problem definition – when policy problems first surface or resurface, and potential solutions are being debated. Indeed, policymakers – and especially those in government - have substantial influence at this phase of agenda- setting, where government is likely to have privileged access to expert knowledge and to public attention. Over the course of the policy cycle, frames can become entrenched, meaning that there is less potential to influence them after the stage of problem definition. Policymakers thus have more scope to explicitly insert scientific considerations into policy frames at the earlier phase of problem definition.\n\n\n\nScience, values and interests. When invoking science, policymakers need to avoid marginalising or crowding out value- and interest-based considerations, or other types of (experiential or lay) knowledge. They should not simply signal that they are ‘following the science’, but need to communicate how they have factored in scientific evidence in combination with a range of other considerations. Failure to do so risks publics (or others, see endnote) simply discounting scientific evidence, as it does not resonate with their concerns and experiences.9\n\n\n\nSelective use of science. There is a risk that highly selective use of science to support value- and interest-based positions may undermine the authority of science. Members of the public are more likely to trust science-informed policy where the evidence base, and its limitations, are set out as clearly as possible – even if this may appear less ‘persuasive’ than a more selective approach. Thus policymakers should be cautious in how they mobilise science in policy communications, especially in areas where there are extensive gaps in knowledge (see also Dimension 3: How science-for-policymaking is communicated).\n\nDimension 2: Types of scientiﬁc sources invoked in policy debate\n\nThe second dimension captures how diﬀerent features of science inﬂuence views of the relevance and trustworthiness of science-for-policymaking. In particular, we looked at the nature of the evidence invoked; and the degree of convergence/divergence in the types of evidence being marshalled. Both the literature and the project’s commissioned research highlight how diﬀerent members of the public may show varying levels of trust in diﬀerent scientiﬁc sources, based on the extent to which evidence is seen as grounded in local understanding and concerns. The evidence also shows that participants may invoke distinct sources of science in debate, which can exacerbate polarisation and create a risk of participants ‘talking past’ each other.\n\nCondition 2.1: The nature of evidence invoked\n\nThe nature of the scientiﬁc evidence used in policymaking, and its implications for public trust, has been much discussed and debated in the literature (see, for example, (Jasanoﬀ, 1990, 2007; Funtowicz and Ravetz, 1993; Nowotny, Gibbons and Scott, 2001; Stirling, 2010; Owens, 2015). A key insight from this literature is that scientiﬁc evidence is itself socially constructed, and diﬀerent types of scientiﬁc evidence']","Policymakers can maintain the authority of science in policy-making by avoiding marginalizing or crowding out value- and interest-based considerations, or other types of knowledge. They should communicate how scientific evidence is factored in along with a range of other considerations, rather than simply stating they are 'following the science'. This approach helps prevent the public from discounting scientific evidence and preserves public trust in science-informed policy.",
How can trust in science for policymaking be maintained and enhanced?,"[' considerations will be elaborated into more speciﬁc recommendations, in partnership with the science- for-policymaking ecosystem, as the next step of the British Academy’s programme of work in this area.\n\nFor public oﬃcials and policy advisors:\n\n1.\n\nSeek to invoke science early on in the framing process, to inﬂuence the extent to which scientiﬁc ﬁndings are part of political debate and policy development. Good examples of this include the case of mpox, which has built on many of the lessons learned through the Covid-19 pandemic response, and there are many examples from environmental policy, including the clean air zones case study this project explored.\n\n2.\n\nAvoid an approach that simply ‘follows the science’, as was communicated at various points of the Covid-19 crisis. Make clear how scientiﬁc evidence has been integrated with a range of other considerations.\n\n3.\n\nPromote transparency in how evidence is used, including through development of a shared transparency framework, for example as proposed in the evidence transparency framework campaign led by Sense about Science and the Institute for Government.\n\n4.\n\nAcknowledge uncertainty and ambiguity, and if evidence is used selectively, explain why. Clarify the quality of evidence which is being used and how gaps in knowledge will be addressed.\n\n5.\n\nProtect and sustain scientiﬁc integrity and independence in the way that science is marshalled in policymaking. This means ensuring advisory bodies retain independence, that their composition and deliberations are transparent as far as possible, but equally that they are not directly responsible for policy decisions.\n\n7\n\nPublic trust in science-for-policymaking\n\nFor researchers and knowledge brokers:\n\n6.\n\nWhere research addresses contested policy issues, ensure sensitivity to diﬀerent perspectives in communicating your ﬁndings. This may require bringing in appropriate expertise about public perspectives and public engagement. The new public engagement ‘Observatories’ are helpfully mapping and facilitating further engagement on key issues.\n\n7.\n\nPlay an active role in helping frame policy issues early on in the debate, clarifying the role of science in understanding and addressing policy challenges. Good examples are the UK Biobank or the Nuﬃeld Council on Bioethics which have sought to anticipate important developments in the biosciences.\n\nFor all engaged in the science-for-policymaking system:\n\n8.\n\nAvoid the ‘information deﬁcit model’: simply providing more evidence is unlikely to shift people’s views. A clear example is the unsuccessful attempt to induce acceptance of Genetically Modiﬁed (GM) food by focusing solely on ‘informing’ the public about the scientiﬁc evidence without taking account of the wider reasons for scepticism.\n\n9.\n\nRecognise and respect the role of local perspectives and knowledge, especially on issues with highly localised implications (such as clean air zones) – and seek to integrate such local knowledge with other forms of scientiﬁc evidence.\n\n10. Avoid contributing to polarisation: explicitly valuing and bringing together\n\ndiﬀerent disciplinary communities can help ensure scientiﬁc ﬁndings are integrated. An integrated evidence base across scientiﬁc disciplines can be more robust and strengthen trust in science-for-policy. This is relevant to both publicly funded, challenge-oriented research programmes, and advisory committees established by government.\n\n8\n\nPublic trust in science-for-policymaking\n\n1. Introduction\n\nScience, used in the broadest sense of the term,2 is invoked to inform policy decisions throughout the policy process – from the identiﬁcation and mapping of policy problems, through to weighing up diﬀerent responses, and assessing the eﬃcacy and impact of policy interventions. Science also plays a key role in public debates on policy, as evident in discussions on complex global challenges such as responding to the Covid-19 pandemic, genetic modiﬁcation, regulating generative AI, or mitigating global warming.\n\nThe prominence of science in policy deliberation makes it crucial to understand when and why people trust the science informing policy. When and why do people consider science to be relevant to informing policy? And what factors are likely to ground public trust in science for policymaking, across diﬀerent types of policy issues?3\n\nWe suggest that these questions are important for the health of public debate and accountability. Where science is a key factor in policymaking, the evidence bases it generates can help foster critical deliberation on policy, potentially enhancing the accountability of policymaking. Conversely']","Trust in science for policymaking can be maintained and enhanced by promoting transparency in how evidence is used, acknowledging uncertainty and ambiguity, protecting and sustaining scientific integrity and independence, recognizing and respecting local perspectives and knowledge, avoiding contributing to polarization, and integrating different disciplinary communities to ensure scientific findings are integrated and robust.",
"How do policy features affect public views on science in policymaking, and how can policymakers shape debates on science through framing?","[' dimensions that inﬂuence public perspectives: features of the policy area, including how it is framed; the types of scientiﬁc sources invoked in debate; how science-for-policymaking is communicated and brokered; and underlying attitudes amongst diﬀerent members of the public (see Methods). Although presented separately, the conditions need to be considered both individually and as mutually dependent parts of a wider system.\n\nDimension 1: Features of the policy area, including how it is framed\n\nTwo aspects of the policy issue are particularly important in inﬂuencing how members of the public view science in policymaking: the way the issue is framed; and the degree and nature of contestation on the issue. The body of evidence on these aspects, as well as the project’s commissioned research, shows that policymakers can have a considerable inﬂuence on framing, and thus how science is invoked in debates. There is a particular window of opportunity for inﬂuencing framing in the initial stages of problem deﬁnition, as new issues are identiﬁed in political debate. We also argue that in highly contested policy areas, it is important to avoid marshalling scientiﬁc evidence in an overly selective way, or doing so in a way that crowds out important values and interests.\n\nCondition 1.1: Framing of the issue\n\nThe wider literature has for many decades called attention to the importance of framing in shaping the role of science in public debate (Rein and Schön, 1991; Schön and Rein, 1994; Hajer, 2003; Science Advice for Policy by European Academies, 2019). Framing refers to the selection and presentation of diﬀerent dimensions of an issue, in a way that promotes particular problem deﬁnitions and solutions and excludes others (Entman, 1993). For example, rising energy prices could be framed in terms of geopolitical threats, welfare and social inequality, or inadequate infrastructure and technology.\n\nFraming is not immutable or ﬁxed, but is subject to change over time, and can be inﬂuenced by policymakers or the actions of intermediary organisations and institutions, including scientists, civil society and the media (Kingdon, 1984). Framing is likely to be especially volatile in the early stages of issue deﬁnition, when new policy problems are ﬁrst identiﬁed or where it resurfaces – for example, through a crisis, or a report setting out new evidence. Following this issue deﬁnition phase, how a policy is framed (or reframed) has important implications for which types of policies are then adopted, and which policy communities and publics participate in debate (Baumgartner and Jones, 2010).\n\nIn the context of this report, the relationship between two types of framing are relevant: science-led framings; and values or interest-led framings. Science-led framing refers to deﬁnitions of issues that emphasise the importance of scientiﬁc knowledge in understanding the problem and identifying solutions. Value- or interest-led framings deﬁne the policy as revolving mainly around issues such as fairness, propriety, or how costs and beneﬁts are allocated across diﬀerent groups.\n\nIn reality, no issue is ever deﬁned solely as value or interest-led, or science-led: all policy issues will invoke some values and interests, and it is diﬃcult to conceive of an issue that does not require some kind of specialised or scientiﬁc knowledge to inform the deﬁnition of, or appropriate responses to the problem. However, the relative emphasis on science as a resource for helping inform policy will vary across policy areas, and over time.\n\n16\n\nPublic trust in science-for-policymaking\n\nThe case of clean air zone policies illustrates how one policy area can be subject to diﬀerent types of framing (Oliver and Pearce, 2023). Some framings of this issue are science-led: the policy is a public health measure to reduce exposure to harmful nitrous oxide pollution and other pollutants like diesel particulates; or it is part of a suite of policies to cut carbon emissions from transport. Other framings are led by values and interests: for example, presenting the policy as part of an anti-car agenda that limits personal freedoms.\n\nPoliticians and especially those in government have a key role in inﬂuencing such framing, and thus the role of science in debate. Political incumbents typically have access to extensive expert knowledge and data, through their civil service and scientiﬁc advisory groups. Politicians and policymakers are also likely to get credit for drawing on such research: the project']","Policy features can influence public views on science in policymaking by framing the issue in a certain way and by the degree and nature of contestation on the issue. Policymakers can shape debates on science through framing by influencing how the issue is presented and defined, particularly in the initial stages of problem definition. They can also avoid selectively using scientific evidence or crowding out important values and interests in highly contested policy areas.",
How does REF impact research quality in UK HEIs and policy-making for public interest?,"['�s Treasury\n\nICS\n\nImpact Case Study\n\nIDR\n\nInterdisciplinary Research\n\nIGO\n\nIntergovernmental Organisation\n\niMATCH\n\nInnovate Manchester Advanced Therapy Centre Hub\n\nIPCC\n\nIntergovernmental Panel on Climate Change\n\nIPM\n\nInstitute of Place Management at Manchester Metropolitan University\n\nIQR\n\nInterquartile range\n\nISFET\n\nIon-Sensitive Field-Effect Transistor-based microsystems\n\nITT\n\nInvitation to Tender\n\nKWIC\n\nKeyword-in-Context approach\n\nLGBTQ\n\nLesbian, Gay, Bisexual, Transgender, Queer or Questioning, Intersex, Asexual, and more\n\nMANDRAKE MANchester DRug Analysis and Knowledge Exchange\n\nMCCA\n\nManchester Climate Change Agency\n\nMCGS\n\nManchester Centre for Gothic Studies\n\nMCYS\n\nManchester Centre for Youth Studies\n\nMMU\n\nManchester Metropolitan University\n\nMRC\n\nMedical Research Council\n\nMSW\n\nMulti-Story Water\n\nNASA\n\nThe National Aeronautics and Space Administration\n\nNCCPE\n\nNational Coordinating Centre for Public Engagement\n\nNDC\n\nNational Decommissioning Centre\n\nNERC\n\nNatural Environment Research Council\n\nNGO\n\nNon-governmental Organisation\n\nxv\n\nxvi\n\nData enhancement and analysis of the REF 2021 Impact Case Studies\n\nNICE\n\nNational Institute for Health and Care Excellence\n\nNIHR\n\nNational Institute for Health and Care Research\n\nNMF\n\nNonnegative Matrix Factorization\n\nNPS\n\nNew Psychoactive Substances\n\nNUTS\n\nNomenclature of Territorial Units for Statistics\n\nOFGEM\n\nThe Office of Gas and Electricity Markets\n\nORCID\n\nOpen Researcher and Contributor Identifier\n\nPAR\n\nParticipatory Action Research\n\nPEM\n\nPolymer Electrolyte Membrane\n\nPHE\n\nPublic Health England\n\nPOC\n\nPoint-Of-Care\n\nPPE\n\nPersonal Protective Equipment\n\nPV\n\nPhotovoltaic\n\nPYP\n\nParticipatory Youth Practice\n\nQR\n\nQuality-related\n\nR&I\n\nResearch and Innovation\n\nREF\n\nResearch Excellence Framework\n\nREG\n\nResearch Excellence Grant\n\nREMAP-CAP A Randomised, Embedded, Multi-factorial, Adaptive Platform Trial for Community-\n\nAcquired Pneumonia\n\nRESIN\n\nClimate-Resilient Cities and Infrastructures\n\nROI\n\nReturn On Investment\n\nRS-IDR\n\nRao-Sterling metric\n\nSAGE\n\nUK Government’s Scientific Advisory Group on Emergencies\n\nSME\n\nSmall-to-Medium-sized Enterprise\n\nSSS\n\nSexuality Summer School by The Centre for the Study of Sexuality and Culture\n\nSTFC\n\nScience and Technology Facilities Council\n\nSVEC\n\nOxford Brookes University’s Sustainable Vehicle Engineering Centre\n\nTF-IDF\n\nTerm Frequency - Inverse Document Frequency\n\nT-MACS\n\nTroponin-only Manchester Acute Coronary Syndromes\n\nTRAC\n\nTransparent Approach to Costing\n\nUCL\n\nUniversity College London\n\nUK\n\nUnited Kingdom\n\nUKRI\n\nUK Research and Innovation\n\nUN\n\nUnited Nations\n\nUNFCCC\n\nUnited Nations Framework Convention on Climate Change\n\nUoA\n\nUnit of Assessment\n\nUSW\n\nUniversity of South Wales\n\nWHO\n\nWorld Health Organization\n\nChapter 1\n\nIntroduction\n\n1\n\n2\n\nData enhancement and analysis of the REF 2021 Impact Case Studies\n\n1.1. Context\n\nThe Research Excellence Framework (REF)7 is a system for assessing the quality of research undertaken in UK Higher Education Institutions (HEIs) and is a key aspect of the UK research landscape. First carried out in 2014, the REF replaced the Research Assessment Exercise and is managed by Research England on behalf of the four UK higher education funding bodies: Research England, the Scottish Funding Council (SFC), the Higher Education Funding Council for Wales (HEFCW), and the Department for the Economy, Northern Ireland (DfE). The REF aims to (i) provide accountability for public investment in research by demonstrating evidence-based benefit, (ii) provide benchmarking information for the HE sector and public information, and (iii) inform the selective allocation of research funding.8 The REF is conducted by a process of expert review by subpanels for each of the 34 subject- based Units of Assessment (UoAs), guided by']","The REF aims to provide accountability for public investment in research by demonstrating evidence-based benefit, provide benchmarking information for the HE sector and public information, and inform the selective allocation of research funding. It is conducted by a process of expert review by subpanels for each of the 34 subject-based Units of Assessment (UoAs), guided by specific criteria and guidelines set by the funding bodies.",
How challenging is it to create impact metrics for diverse research activities?,"[', illustrating that impact was often a bespoke activity. Given these impact pathways’ diversity, developing a balanced and comprehensive set of impact metrics that capture this range of activities would be challenging. The results demonstrate the numerous, complex and often unique impact pathways involved.\n\n21\n\nKing’s College London and Digital Science (2015).\n\n22\n\nFoR codes are a classification system managed by the Australia and New Zealand Classification (ANZSRC) to group research, researchers and their outputs by discipline. They are commonly used in bibliometric analyses to classify research outputs’ disciplines, and can be applied at three nested levels reflecting the classification’s granularity: six- digit codes (the most granular), four-digit codes and two-digit codes (the least granular). We used four-digit codes in this analysis.\n\n15\n\n0101: Pure Mathematics\n\n0102: Applied Mathematics\n\n0103: Numerical and Computational Mathematics\n\n0104: Statistics\n\n0105: Mathematical Physics\n\n0199: Other Mathematical Sciences\n\n0201: Astronomical and Space Sciences\n\n0202: Atomic, Molecular, Nuclear, Particle and Plasma Physics\n\n0203: Classical Physics\n\n0204: Condensed Matter Physics\n\n0205: Optical Physics\n\n0206: Quantum Physics\n\n1: Public Health and Health Services\n\n0299: Other Physical Sciences\n\n0301: Analytical Chemistry\n\n0: Public health\n\n0302: Inorganic Chemistry\n\n16: NHS\n\n0303: Macromolecular and Materials Chemistry\n\n26: Dentistry\n\n0304: Medicinal and Biomolecular Chemistry\n\n38: Sexually transmitted infections and HIV\n\n0305: Organic Chemistry\n\n40: Dementia and Alzheimer’s\n\n0306: Physical Chemistry (Incl. Structural)\n\n0307: Theoretical and Computational Chemistry\n\n44: Mental health\n\n0399: Other Chemical Sciences\n\n0401: Atmospheric Sciences\n\n60: Social services and primary care\n\n0402: Geochemistry\n\n0403: Geology\n\n0404: Geophysics\n\n2: Clinical Medicine\n\n0405: Oceanography\n\n0406: Physical Geography and Environmental Geoscience\n\n1: Treatment and disease\n\n0499: Other Earth Sciences\n\n0501: Ecological Applications\n\n0502: Environmental Science and Management\n\n10: Cancer diagnostics and therapy\n\n0503: Soil Sciences\n\n0599: Other Environmental Sciences\n\n20: Drug discovery and clinical trials\n\nUoA 1: Clinical Medicine\n\n0601: Biochemistry and Cell Biology\n\n28: Viruses and vaccination\n\n0602: Ecology\n\n29: Stroke and brain injury\n\n0603: Evolutionary Biology\n\n45: Genetic testing and diagnostics\n\n0604: Genetics\n\n0605: Microbiology\n\n58: Diabetes\n\nUoA 2: Public Health, Health Servicesand Primary Care\n\n0606: Physiology\n\n71: Health screening and preventative treatment\n\n0607: Plant Biology\n\n0608: Zoology\n\n76: Infectious disease\n\nUoA 3: Allied Health Professions, Dentistry, Nursing and Pharmacy\n\n0699: Other Biological Sciences\n\n0701: Agriculture, Land and Farm Management\n\n0702: Animal Production\n\n3: Energy, Environment and Engineering\n\n0703: Crop and Pasture Production\n\n11: Climate change\n\n0704: Fisheries Sciences\n\n0705: Forestry Sciences\n\n30: Pollution and air quality\n\n0706: Horticultural Production\n\nUoA 4: Psychology, Psychiatry and Neuroscience\n\n0707: Veterinary Sciences\n\n42: Energy\n\n0799: Other Agricultural and Veterinary Sciences\n\n51: Nuclear energy and research\n\n0801: Artificial Intelligence and Image Processing\n\n55: Environmental sustainability\n\n0802: Computation Theory and Mathematics\n\n0803: Computer Software\n\n70: Engineering\n\n0804: Data Format\n\nUoA 5: Biological Sciences\n\n0805: Distributed Computing\n\n74: Manufacturing and emissions\n\n0806: Information Systems\n\n0807: Library and Information Studies\n\n4: Information, Applied Technology and Analytics\n\nUoA 6: Agriculture, Food and Veterinary Sciences\n\n0899: Other Information and Computing Sciences\n\n0901: Aerospace Engineering\n\n2: Computing and software development\n\n0902: Automotive Engineering\n\n0903: Biomedical Engineering\n\nUoA 7: Earth Systems and Environmental Sciences\n\n3: Applied technology\n\n0904: Chemical Engineering\n\n0905: Civil Engineering\n\n39: Computer science and data analysis\n\n']",Developing a balanced and comprehensive set of impact metrics that capture the range of diverse research activities would be challenging due to the bespoke nature of impact pathways and the complexity involved.,
How does the REF evaluate research quality at UK HEIs and involve expert review by subpanels and main panels across UoAs?,"[' a not-for-profit research organisation that aims to improve policy and decision making in the public interest, through research and analysis. RAND Europe’s clients include European governments, institutions, non-governmental organisations and firms with a need for rigorous, independent, multidisciplinary analysis. Electric Data Solutions provides bespoke analysis to universities, funders and publishers to help them understand their unique contribution to the global research system. Different Angles Ltd is a consultancy that focuses on the social impact of universities and research.\n\nFor more information about RAND Europe or this document, please contact:\n\nSue Guthrie (Director, Science and Emerging Technology) RAND Europe Eastbrook House, Shaftesbury Road Cambridge CB2 8DR United Kingdom Email: sguthrie@randeurope.org\n\nii\n\nData enhancement and analysis of the REF 2021 Impact Case Studies\n\nExecutive summary\n\nThe Research Excellence Framework (REF)2 is a system for assessing the quality of research undertaken in UK Higher Education Institutions (HEIs) and a key aspect of the UK research landscape. Institutions make submissions that are assessed through expert review by subpanels for the 34 subject-based Units of Assessment (UoAs) under the guidance of four main panels: Panel A (Medicine, health and life sciences), Panel B (Physical sciences, engineering and mathematics), Panel C (Social sciences) and Panel D (Arts and humanities). This assessment is based on the quality of research outputs, the impact of research beyond academia, and the environment supporting research. REF defines impact as ‘the effect on, change or benefit to the economy, society, culture, public policy or services, health, the environment or quality of life, beyond academia’.3 REF 2014 and REF 2021 used Impact Case Studies (ICSs) to help assess research impact beyond academia. ICSs are short five-page documents detailing a project’s impact and underpinning research.\n\nThe corpus of over 6,000 REF 2021 ICSs provides a rich resource for analysis and showcases the research undertaken at UK HEIs. This study aimed to analyse these ICSs to investigate their research impact’s nature and beneficiaries, underpinning research and\n\nrelationship to the UK government’s priority policy areas. Where appropriate, the study also analyses the differences between REF ICSs submitted in 2021 vs. 2014.\n\nWe used a diverse methodological approach building on a previous analysis of the 2014 REF ICSs.4 The work comprises a mix of quantitative and qualitative methods, including topic modelling, text searches, analysis of ICS- associated metadata, bibliometric analysis and qualitative analysis of ICS content. We also conducted several deep dives examining ICSs relating to three policy priorities: COVID-19, net zero and Place.5 Below, we outline our key findings from the analysis.\n\nUK HEIs have had a significant and diverse societal impact\n\nOne key observation when reading and reviewing a sample of ICSs is that research at UK HEIs has significantly impacted society and the economy in the UK and globally. This study’s analyses reinforce this conclusion. HEIs’ research impacts were diverse, spanning 79 unique impact topics ranging from ‘cancer diagnostics and therapy’ and ‘intelligence and cyber security’ to ‘pollution and air quality’ and ‘language and linguistics’.\n\n2\n\nResearch Excellence Framework (2023d).\n\n3\n\nResearch Excellence Framework (2022).\n\n4\n\nKing’s College London and Digital Science (2015).\n\n5\n\nThis refers to the broad political priority area around regional and geographical inequality, also referred to as ‘levelling up’.\n\nImpact pathways are complex, diverse and unique\n\nWe explored pathways from research to impact by linking the underpinning research in the ICSs with the corresponding impact topics and UoAs. The detailed alluvial diagram in Figure 1 illustrates the results, showing that impact arises from various disciplines; ICSs across all four main REF Panels (A–D) contributed to the impact topics. Examining the underpinning research disciplines showed that 72% of ICSs were based on publications with two or more Fields of Research (FoRs). Mapping out the different impact routes shows that no single pathway exists. Given the diversity of impact pathways, developing a balanced and comprehensive set of impact metrics to capture this range of activities would be challenging.\n\nImpact was global, national and local\n\nResearch at UK HEIs has had an impact globally, with almost every country benefitting from the research (Figure 2). Moreover, exploring the ‘flow’ of impact between UK regions showed that impact was often ‘exported’ from the region where the research was conducted to other UK areas. The South East of England was the biggest ‘exporter�']","The Research Excellence Framework (REF) evaluates research quality at UK Higher Education Institutions (HEIs) by assessing submissions through expert review by subpanels for the 34 subject-based Units of Assessment (UoAs) under the guidance of four main panels: Panel A (Medicine, health and life sciences), Panel B (Physical sciences, engineering and mathematics), Panel C (Social sciences), and Panel D (Arts and humanities). This assessment is based on the quality of research outputs, the impact of research beyond academia, and the environment supporting research.",
